{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OhO4xlwqExT"
   },
   "source": [
    "# Publaynet BERT Classifier\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQpJTV7RSVZW"
   },
   "source": [
    "## Environment Setup\n",
    "Import key libraries and working envorinments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-GlywkSFegL"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers==4.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.2.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "979OUro5Eac3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "#from transformers.configuration_bert import BertConfig\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7TWqvbTppX_"
   },
   "source": [
    "##Get Training and Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('funsd/funsd_train_list_dict.json', 'r') as fp:\n",
    "    train_list_dict = json.load(fp)\n",
    "\n",
    "with open('funsd/funsd_test_list_dict.json', 'r') as fp:\n",
    "    eval_list_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['92091873', '91939637', '87533049', '01073843', '92586242', '0012529284', '71341634', '0001477983', '91315069_91315070', '0060207528', '91161344_91161347', '71366499', '00922237', '91355841', '93380187', '01150773_01150774', '0060165115', '91914407', '92081358_1359', '660978', '0011974919', '81749056_9057', '00093726', '0000999294', '81186212', '0060077689', '87672097', '11875011', '00851772_1780', '0011859695', '81619511_9513', '0001456787', '81310636', '0060080406', '0011973451', '91104867', '00836244', '0001476912', '12052385', '0060255888', '71206427', '0012199830', '0001463448', '0000990274', '716552', '00920222', '0012529295', '80728670', '93213298', '71108371', '0001209043', '88057519', '01191071_1072', '00836816', '91361993', '92298125', '00040534', '0011838621', '0060029036', '0000989556', '0060024314', '0001129658', '0071032790', '00838511_00838525', '87682908', '0060214859', '00070353', '93351929_93351931', '0001438955', '81619486_9488', '00920294', '0000971160', '0012947358', '00865872', '91391286', '01122115', '01408099_01408101', '80310840a', '0012602424', '0071032807', '0060308251', '92094746', '0060302201', '0060094595', '71190280', '92433599_92433601', '0060091229', '89386032', '91974562', '92094751', '89817999_8002', '71601299', '00851879', '92039708_9710', '92657391', '80718412_8413', '00860012_00860014', '93329540', '0060068489', '12603270', '0060308461', '0060270727', '00837285', '91356315', '0011899960', '82254638', '0001118259', '0011906503', '91391310', '01197604', '80707440_7443', '11508234', '0011845203', '0060262650', '0060173256', '88547278_88547279', '0001123541', '81574683', '0001239897', '0011856542', '0060025670', '89867723', '0012178355', '91856041_6049', '93455715', '0011976929', '0060007216', '0001485288', '0001463282', '0030041455', '71202511', '92327794', '0060136394', '89368010', '92314414', '92657311_7313', '13149651', '91903177', '71563825', '00283813', '00866042', '0060036622', '0011505151', '0013255595', '0030031163', '91581919', '91372360', '12825369', '0060000813'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['82837252', '85201976', '86263525', '82251504', '93106788', '82573104', '87528321', '85240939', '82562350', '82253245_3247', '87093315_87093318', '83443897', '87332450', '89856243', '83635935', '82250337_0338', '82200067_0069', '92380595', '86236474_6476', '82491256', '85540866', '86244113', '83823750', '83594639', '87528380', '86220490', '87086073', '87147607', '82252956_2958', '83641919_1921', '82253058_3059', '87125460', '83624198', '82504862', '86328049_8050', '82254765', '86079776_9777', '83553333_3334', '83573282', '87137840', '87428306', '86230203_0206', '87594142_87594144', '91814768_91814769', '86075409_5410', '83772145', '82253362_3364', '85629964', '82092117', '83996357'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_list_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 7412,\n",
       " 'box': [140, 186, 179, 200],\n",
       " 'category': 'question',\n",
       " 'text': 'DATE:',\n",
       " 'relations': {'0': {'name': 'answer', 'id': 8473, 'object': 7421}},\n",
       " 'gcn_bert_large': [0.057231076061725616,\n",
       "  0.04367358982563019,\n",
       "  0.04971188306808472,\n",
       "  -0.00449754111468792,\n",
       "  0.00840899720788002,\n",
       "  0.020118363201618195,\n",
       "  0.04725451394915581,\n",
       "  0.0016711237840354443,\n",
       "  -0.005014966242015362,\n",
       "  0.0278470516204834,\n",
       "  0.06539274752140045,\n",
       "  0.020788487046957016,\n",
       "  -0.005496850237250328,\n",
       "  0.0006100722239352763,\n",
       "  0.04117555916309357,\n",
       "  0.04269300401210785,\n",
       "  0.07025939226150513,\n",
       "  0.05321888253092766,\n",
       "  0.0472104549407959,\n",
       "  0.048451147973537445,\n",
       "  0.010146746411919594,\n",
       "  -0.00772374402731657,\n",
       "  -0.003857735078781843,\n",
       "  0.0560426339507103,\n",
       "  0.046066343784332275,\n",
       "  0.010603458620607853,\n",
       "  -0.006646316032856703,\n",
       "  0.03853141516447067,\n",
       "  -0.004647953435778618,\n",
       "  0.05285662040114403,\n",
       "  0.05691283941268921,\n",
       "  0.059824779629707336,\n",
       "  0.05756156146526337,\n",
       "  0.050120726227760315,\n",
       "  0.07251019775867462,\n",
       "  -0.0014099960681051016,\n",
       "  0.0547151193022728,\n",
       "  0.05400951951742172,\n",
       "  0.010034391656517982,\n",
       "  0.04290659725666046,\n",
       "  0.06579145044088364,\n",
       "  -0.0056360806338489056,\n",
       "  0.04311913624405861,\n",
       "  0.0462476871907711,\n",
       "  -0.0010045599192380905,\n",
       "  0.05396832153201103,\n",
       "  0.020849822089076042,\n",
       "  0.0413055494427681,\n",
       "  5.260802572593093e-05,\n",
       "  0.0509210079908371,\n",
       "  0.002460242249071598,\n",
       "  0.05495474487543106,\n",
       "  0.036387428641319275,\n",
       "  0.0021932299714535475,\n",
       "  0.03976290673017502,\n",
       "  0.04311436414718628,\n",
       "  0.04630018025636673,\n",
       "  -0.0038955830968916416,\n",
       "  -0.001207517459988594,\n",
       "  -0.006169172935187817,\n",
       "  0.045013293623924255,\n",
       "  0.0007044399972073734,\n",
       "  0.0366322323679924,\n",
       "  0.0007339127478189766,\n",
       "  -0.0052226753905415535,\n",
       "  -0.001393479062244296,\n",
       "  0.05835763365030289,\n",
       "  0.04694972187280655,\n",
       "  0.0016304010059684515,\n",
       "  -0.003746815724298358,\n",
       "  0.05156540125608444,\n",
       "  0.045010872185230255,\n",
       "  0.027145851403474808,\n",
       "  0.043716613203287125,\n",
       "  0.03877663239836693,\n",
       "  0.04803134873509407,\n",
       "  -0.004770610481500626,\n",
       "  0.07822872698307037,\n",
       "  0.017023775726556778,\n",
       "  0.010301616042852402,\n",
       "  0.059531792998313904,\n",
       "  0.021336041390895844,\n",
       "  0.01565043069422245,\n",
       "  0.0568542405962944,\n",
       "  0.04065706580877304,\n",
       "  0.04656800627708435,\n",
       "  0.03059982694685459,\n",
       "  -0.002890857867896557,\n",
       "  -0.0036459513939917088,\n",
       "  0.0012288657017052174,\n",
       "  0.06295135617256165,\n",
       "  -4.102312959730625e-05,\n",
       "  0.04766956716775894,\n",
       "  0.05365603417158127,\n",
       "  0.000541231594979763,\n",
       "  0.029135119169950485,\n",
       "  0.03512410819530487,\n",
       "  0.046362292021512985,\n",
       "  -0.0047833481803536415,\n",
       "  2.3736254661343992e-05,\n",
       "  0.055398304015398026,\n",
       "  0.034992292523384094,\n",
       "  0.0430055670440197,\n",
       "  0.040054596960544586,\n",
       "  0.014363173395395279,\n",
       "  0.02187531813979149,\n",
       "  0.027137935161590576,\n",
       "  0.042907584458589554,\n",
       "  -0.005326581187546253,\n",
       "  0.0355532169342041,\n",
       "  0.045465897768735886,\n",
       "  0.00016090628923848271,\n",
       "  -0.0036609796807169914,\n",
       "  -0.005863160360604525,\n",
       "  -0.004230409394949675,\n",
       "  0.04270170256495476,\n",
       "  0.034391578286886215,\n",
       "  -0.0001319545553997159,\n",
       "  -0.0004582535766530782,\n",
       "  0.03280998021364212,\n",
       "  0.04665173590183258,\n",
       "  0.04140358418226242,\n",
       "  0.05423513054847717,\n",
       "  0.05949578434228897,\n",
       "  0.02775999903678894,\n",
       "  0.00019157826318405569,\n",
       "  0.024955302476882935,\n",
       "  0.053882744163274765,\n",
       "  0.05923081934452057,\n",
       "  0.045325055718421936,\n",
       "  -0.004636128433048725,\n",
       "  0.010841267183423042,\n",
       "  0.04284348338842392,\n",
       "  0.044404514133930206,\n",
       "  0.04213809221982956,\n",
       "  -0.004496244713664055,\n",
       "  0.0005151798250153661,\n",
       "  0.05069545656442642,\n",
       "  0.001168782589957118,\n",
       "  0.06462450325489044,\n",
       "  0.010745702311396599,\n",
       "  0.04482375085353851,\n",
       "  0.03481260687112808,\n",
       "  -0.002909454982727766,\n",
       "  0.051274433732032776,\n",
       "  0.03519415855407715,\n",
       "  -0.004907572641968727,\n",
       "  0.058013319969177246,\n",
       "  -0.00522581348195672,\n",
       "  0.030532965436577797,\n",
       "  0.03783056139945984,\n",
       "  0.03564593195915222,\n",
       "  0.045291174203157425,\n",
       "  0.04666672646999359,\n",
       "  0.028725406154990196,\n",
       "  -0.004708642140030861,\n",
       "  0.04774175211787224,\n",
       "  0.042633187025785446,\n",
       "  0.0004886160022579134,\n",
       "  0.03338002413511276,\n",
       "  0.04033732786774635,\n",
       "  0.0005732089630328119,\n",
       "  -0.0004586747963912785,\n",
       "  0.0382930226624012,\n",
       "  1.6988728020805866e-05,\n",
       "  0.025088470429182053,\n",
       "  0.06890527904033661,\n",
       "  0.044268518686294556,\n",
       "  0.03348780423402786,\n",
       "  -0.004624572116881609,\n",
       "  0.04261332005262375,\n",
       "  -0.005295941140502691,\n",
       "  0.0498247891664505,\n",
       "  0.0425376258790493,\n",
       "  0.041885219514369965,\n",
       "  -0.005354645196348429,\n",
       "  0.051614269614219666,\n",
       "  -0.0007139128865674138,\n",
       "  0.005837026052176952,\n",
       "  0.03425610437989235,\n",
       "  0.009061413817107677,\n",
       "  0.044110797345638275,\n",
       "  -0.0053210267797112465,\n",
       "  -0.0011540756095200777,\n",
       "  0.0207723006606102,\n",
       "  0.045049406588077545,\n",
       "  0.04731243476271629,\n",
       "  0.0012692381860688329,\n",
       "  0.0836557149887085,\n",
       "  0.05364968627691269,\n",
       "  -0.000990924658253789,\n",
       "  0.047362640500068665,\n",
       "  0.05434190481901169,\n",
       "  -0.003394404659047723,\n",
       "  0.047372378408908844,\n",
       "  -0.005702330730855465,\n",
       "  0.0012611134443432093,\n",
       "  0.0473158173263073,\n",
       "  0.03818543255329132,\n",
       "  0.06466647982597351,\n",
       "  0.04732813686132431,\n",
       "  0.04841268062591553,\n",
       "  -0.001500767539255321,\n",
       "  -0.006501415278762579,\n",
       "  0.052169930189847946,\n",
       "  0.04259318858385086,\n",
       "  0.07183222472667694,\n",
       "  0.07147584855556488,\n",
       "  0.001268131542019546,\n",
       "  -0.005971458740532398,\n",
       "  0.045863885432481766,\n",
       "  0.04204309731721878,\n",
       "  -0.00020078005036339164,\n",
       "  -0.0023857043124735355,\n",
       "  0.059328842908144,\n",
       "  -0.00681551918387413,\n",
       "  0.0023171373177319765,\n",
       "  -0.004109074827283621,\n",
       "  -0.0013273274526000023,\n",
       "  -0.004307955503463745,\n",
       "  0.06213216483592987,\n",
       "  0.022461026906967163,\n",
       "  0.014967907220125198,\n",
       "  0.06110401451587677,\n",
       "  0.035300493240356445,\n",
       "  0.05116739869117737,\n",
       "  -0.004236393142491579,\n",
       "  0.0004518143250606954,\n",
       "  0.054898038506507874,\n",
       "  0.015267590060830116,\n",
       "  0.03653767704963684,\n",
       "  0.06922402232885361,\n",
       "  0.03478952497243881,\n",
       "  -0.0022024570498615503,\n",
       "  0.04621795564889908,\n",
       "  0.001126764458604157,\n",
       "  3.2189651392400265e-05,\n",
       "  -0.0049060070887207985,\n",
       "  -0.006098800338804722,\n",
       "  -0.004613776691257954,\n",
       "  -0.0019394016126170754,\n",
       "  0.011929208412766457,\n",
       "  -0.0010742507874965668,\n",
       "  0.006584111601114273,\n",
       "  0.03839042782783508,\n",
       "  0.03161993622779846,\n",
       "  -0.00031280244002118707,\n",
       "  0.06341801583766937,\n",
       "  -0.0029944994021207094,\n",
       "  0.00023382366634905338,\n",
       "  0.0009555474389344454,\n",
       "  -0.0009224325767718256,\n",
       "  -0.0013391602551564574,\n",
       "  0.021532170474529266,\n",
       "  0.03865475207567215,\n",
       "  0.0005554542294703424,\n",
       "  -0.005371318198740482,\n",
       "  0.06241852790117264,\n",
       "  -0.004746539052575827,\n",
       "  -0.0022748128976672888,\n",
       "  0.04606509208679199,\n",
       "  0.052165575325489044,\n",
       "  0.04020904004573822,\n",
       "  0.04334722459316254,\n",
       "  0.001004207180812955,\n",
       "  -0.0028223295230418444,\n",
       "  0.0019113440066576004,\n",
       "  -0.004553046077489853,\n",
       "  -0.0057560475543141365,\n",
       "  -0.004011197946965694,\n",
       "  0.002602933207526803,\n",
       "  6.157078314572573e-05,\n",
       "  0.04126279428601265,\n",
       "  0.0526428259909153,\n",
       "  0.011460565961897373,\n",
       "  0.033837758004665375,\n",
       "  0.0586501881480217,\n",
       "  0.009972333908081055,\n",
       "  -0.000292888842523098,\n",
       "  -0.004705558065325022,\n",
       "  0.0009892728412523866,\n",
       "  0.0016196123324334621,\n",
       "  0.04560565948486328,\n",
       "  0.05871639400720596,\n",
       "  0.05717312544584274,\n",
       "  -0.004034859593957663,\n",
       "  0.0005307287210598588,\n",
       "  0.0005874968483112752,\n",
       "  0.025039874017238617,\n",
       "  0.05359392613172531,\n",
       "  -0.0033801840618252754,\n",
       "  0.05530773103237152,\n",
       "  0.04624932259321213,\n",
       "  0.03725700452923775,\n",
       "  0.04904361069202423,\n",
       "  0.04267539829015732,\n",
       "  0.053026266396045685,\n",
       "  0.0011803398374468088,\n",
       "  -0.006374388001859188,\n",
       "  0.05602434650063515,\n",
       "  0.05404946953058243,\n",
       "  0.021187584847211838,\n",
       "  0.05924097076058388,\n",
       "  0.0002437019720673561,\n",
       "  0.048144400119781494,\n",
       "  0.05068592727184296,\n",
       "  0.010356131941080093,\n",
       "  0.04753587394952774,\n",
       "  -0.0028765774331986904,\n",
       "  -0.005776531994342804,\n",
       "  0.045279838144779205,\n",
       "  0.04808575659990311,\n",
       "  0.06027279049158096,\n",
       "  0.05443312227725983,\n",
       "  -0.004977765493094921,\n",
       "  -0.004475636873394251,\n",
       "  0.014384365640580654,\n",
       "  0.03913962468504906,\n",
       "  0.061858974397182465,\n",
       "  0.0003018505813088268,\n",
       "  -0.0010667560854926705,\n",
       "  0.05269414931535721,\n",
       "  0.06737996637821198,\n",
       "  0.013967988081276417,\n",
       "  0.05014485865831375,\n",
       "  0.047417692840099335,\n",
       "  0.05307988077402115,\n",
       "  0.002753986045718193,\n",
       "  0.007163493428379297,\n",
       "  0.03277437388896942,\n",
       "  0.024367250502109528,\n",
       "  0.05379369854927063,\n",
       "  0.0626012459397316,\n",
       "  0.04966534674167633,\n",
       "  0.052017226815223694,\n",
       "  0.012155517004430294,\n",
       "  -0.005867921747267246,\n",
       "  -0.0016972245648503304,\n",
       "  0.0025318684056401253,\n",
       "  0.06229440122842789,\n",
       "  0.04482102394104004,\n",
       "  0.004698991775512695,\n",
       "  0.042451128363609314,\n",
       "  0.011368821375072002,\n",
       "  0.038813985884189606,\n",
       "  0.02099333517253399,\n",
       "  0.04295620322227478,\n",
       "  -0.006607670336961746,\n",
       "  0.04502703994512558,\n",
       "  0.0009777667000889778,\n",
       "  0.012789951637387276,\n",
       "  0.060206055641174316,\n",
       "  -0.0036823172122240067,\n",
       "  0.03374507278203964,\n",
       "  0.0021433518268167973,\n",
       "  0.08743391185998917,\n",
       "  0.05422239750623703,\n",
       "  0.01678665541112423,\n",
       "  0.04556301236152649,\n",
       "  0.035076431930065155,\n",
       "  0.03610779345035553,\n",
       "  0.05045924335718155,\n",
       "  0.054759539663791656,\n",
       "  -0.00603068433701992,\n",
       "  0.05363333597779274,\n",
       "  -0.0006000895518809557,\n",
       "  0.04300319030880928,\n",
       "  0.04812086373567581,\n",
       "  0.04616605490446091,\n",
       "  -0.004676005803048611,\n",
       "  0.016248922795057297,\n",
       "  0.04853147268295288,\n",
       "  0.0017297505401074886,\n",
       "  0.0410456657409668,\n",
       "  0.0007094250759109855,\n",
       "  -0.0040575060993433,\n",
       "  -0.004881305154412985,\n",
       "  0.04367949068546295,\n",
       "  -0.005692045204341412,\n",
       "  0.04265803471207619,\n",
       "  -0.0034075379371643066,\n",
       "  -0.0029572355560958385,\n",
       "  -0.000976751558482647,\n",
       "  0.049297481775283813,\n",
       "  0.002193481894209981,\n",
       "  0.03401033952832222,\n",
       "  0.05387759208679199,\n",
       "  0.05434751510620117,\n",
       "  0.03492572903633118,\n",
       "  -0.0017750433180481195,\n",
       "  0.0005292651476338506,\n",
       "  0.054131437093019485,\n",
       "  0.03854425996541977,\n",
       "  -0.0008711047121323645,\n",
       "  -0.004013103898614645,\n",
       "  0.0162547267973423,\n",
       "  -0.004348892718553543,\n",
       "  -0.0032686744816601276,\n",
       "  0.03763369470834732,\n",
       "  0.06020420789718628,\n",
       "  -0.004360907711088657,\n",
       "  0.029371902346611023,\n",
       "  0.000867336755618453,\n",
       "  0.009404403157532215,\n",
       "  0.012329140678048134,\n",
       "  0.059383366256952286,\n",
       "  0.06316401064395905,\n",
       "  -0.0009985021315515041,\n",
       "  0.0416833758354187,\n",
       "  0.035184890031814575,\n",
       "  -0.002440209500491619,\n",
       "  0.060367487370967865,\n",
       "  0.04265577718615532,\n",
       "  0.036551907658576965,\n",
       "  0.009452205151319504,\n",
       "  0.00023501238320022821,\n",
       "  0.049746010452508926,\n",
       "  0.001216535223647952,\n",
       "  0.03986333683133125,\n",
       "  0.0008027513977140188,\n",
       "  0.051700789481401443,\n",
       "  0.0006655079196207225,\n",
       "  0.0005264204228296876,\n",
       "  0.03333951160311699,\n",
       "  -0.004118889104574919,\n",
       "  0.046926043927669525,\n",
       "  0.021135006099939346,\n",
       "  0.04600900411605835,\n",
       "  0.010543501004576683,\n",
       "  -0.004568529315292835,\n",
       "  0.06188325583934784,\n",
       "  0.059506844729185104,\n",
       "  0.04590417444705963,\n",
       "  0.0047224536538124084,\n",
       "  0.07306690514087677,\n",
       "  -0.003552434965968132,\n",
       "  0.05550159886479378,\n",
       "  0.0011613386450335383,\n",
       "  0.0030973462853580713,\n",
       "  -0.004088075365871191,\n",
       "  0.015087710693478584,\n",
       "  -0.0005943244323134422,\n",
       "  0.05277712643146515,\n",
       "  0.07786549627780914,\n",
       "  0.02022385224699974,\n",
       "  0.0003155307495035231,\n",
       "  -0.0033784066326916218,\n",
       "  0.0003728952433448285,\n",
       "  0.0012151895789429545,\n",
       "  0.04993631690740585,\n",
       "  0.03442602604627609,\n",
       "  -0.004469683859497309,\n",
       "  0.05906210094690323,\n",
       "  0.05565112456679344,\n",
       "  0.06349228322505951,\n",
       "  0.04317479580640793,\n",
       "  0.00034802249865606427,\n",
       "  0.05359945446252823,\n",
       "  0.05886063724756241,\n",
       "  0.04034431278705597,\n",
       "  0.00021564288181252778,\n",
       "  0.05583184212446213,\n",
       "  -0.00020648681675083935,\n",
       "  0.07272288203239441,\n",
       "  -0.004057353362441063,\n",
       "  0.062494538724422455,\n",
       "  0.03542448580265045,\n",
       "  0.06095542758703232,\n",
       "  0.05112069845199585,\n",
       "  -0.003899927483871579,\n",
       "  0.0528721809387207,\n",
       "  0.0014894336927682161,\n",
       "  -0.003956898115575314,\n",
       "  -0.004853967577219009,\n",
       "  0.05276377126574516,\n",
       "  0.034122973680496216,\n",
       "  0.03709721565246582,\n",
       "  0.07365208864212036,\n",
       "  0.03434353321790695,\n",
       "  0.02645651251077652,\n",
       "  0.00021130323875695467,\n",
       "  0.043742090463638306,\n",
       "  0.006172745954245329,\n",
       "  -0.0035296427085995674,\n",
       "  0.045099660754203796,\n",
       "  0.05575869232416153,\n",
       "  0.02743762731552124,\n",
       "  0.006728623062372208,\n",
       "  0.042514413595199585,\n",
       "  -3.758716047741473e-05,\n",
       "  -0.0044067311100661755,\n",
       "  0.032867833971977234,\n",
       "  0.000422142562456429,\n",
       "  0.003760931547731161,\n",
       "  0.024694591760635376,\n",
       "  -1.3262033462524414e-06,\n",
       "  0.041114144027233124,\n",
       "  0.01867838203907013,\n",
       "  0.01430094800889492,\n",
       "  0.020308464765548706,\n",
       "  0.006878838874399662,\n",
       "  0.0012685991823673248,\n",
       "  -0.003639998147264123,\n",
       "  0.00030615361174568534,\n",
       "  -0.0006057766731828451,\n",
       "  0.051554061472415924,\n",
       "  -0.0007036618189886212,\n",
       "  -0.0008509759791195393,\n",
       "  -0.0006365190492942929,\n",
       "  -0.004714979790151119,\n",
       "  -0.004145259037613869,\n",
       "  0.04002796858549118,\n",
       "  0.04180775582790375,\n",
       "  0.04134437441825867,\n",
       "  0.009027643129229546,\n",
       "  0.002596287988126278,\n",
       "  -0.00552410027012229,\n",
       "  -0.0059226336888968945,\n",
       "  0.022033225744962692,\n",
       "  0.05910283327102661,\n",
       "  0.032772891223430634,\n",
       "  0.0007631870685145259,\n",
       "  -0.002953226212412119,\n",
       "  0.009809959679841995,\n",
       "  0.03642896190285683,\n",
       "  0.051491256803274155,\n",
       "  0.056840427219867706,\n",
       "  0.04336155951023102,\n",
       "  0.0011985182063654065,\n",
       "  -0.0003742534318007529,\n",
       "  0.035032324492931366,\n",
       "  0.003867620136588812,\n",
       "  -0.00010567952995188534,\n",
       "  0.0307319276034832,\n",
       "  0.05500929057598114,\n",
       "  0.05751151219010353,\n",
       "  0.030132941901683807,\n",
       "  0.002607212867587805,\n",
       "  0.050956424325704575,\n",
       "  0.018702208995819092,\n",
       "  0.04765594005584717,\n",
       "  -0.005133644677698612,\n",
       "  -0.00032467657001689076,\n",
       "  0.03915936499834061,\n",
       "  0.0341661274433136,\n",
       "  -0.0002755656896624714,\n",
       "  0.04303856939077377,\n",
       "  0.0536767914891243,\n",
       "  -0.0030692126601934433,\n",
       "  -0.0014331075362861156,\n",
       "  0.03680432215332985,\n",
       "  0.040555402636528015,\n",
       "  -0.00017793287406675518,\n",
       "  -5.1387760322541e-05,\n",
       "  0.04060502350330353,\n",
       "  -0.004909001290798187,\n",
       "  0.0019289342453703284,\n",
       "  0.04955914616584778,\n",
       "  0.007677184883505106,\n",
       "  0.001189903006888926,\n",
       "  0.00042787808342836797,\n",
       "  0.007007490377873182,\n",
       "  0.04424052685499191,\n",
       "  0.0006767827435396612,\n",
       "  0.061339229345321655,\n",
       "  0.0396258682012558,\n",
       "  -0.004102275241166353,\n",
       "  0.047207124531269073,\n",
       "  -0.00013945845421403646,\n",
       "  -0.0011889759916812181,\n",
       "  0.04235287755727768,\n",
       "  0.054522931575775146,\n",
       "  -0.0001883774239104241,\n",
       "  0.02307507023215294,\n",
       "  0.020177209749817848,\n",
       "  0.05059727281332016,\n",
       "  0.04293982684612274,\n",
       "  0.020620733499526978,\n",
       "  0.04916773736476898,\n",
       "  0.009183591231703758,\n",
       "  -0.00031849235529080033,\n",
       "  0.0012518723960965872,\n",
       "  -0.004785981494933367,\n",
       "  0.03189939260482788,\n",
       "  0.04880265146493912,\n",
       "  0.030451413244009018,\n",
       "  0.05320871248841286,\n",
       "  0.003679565154016018,\n",
       "  0.0011183384340256453,\n",
       "  0.023642895743250847,\n",
       "  0.04065432399511337,\n",
       "  0.04692750424146652,\n",
       "  0.04340089485049248,\n",
       "  0.0005980852292850614,\n",
       "  0.04080446437001228,\n",
       "  -0.003925290424376726,\n",
       "  0.05978114902973175,\n",
       "  0.00015428574988618493,\n",
       "  0.04791354387998581,\n",
       "  0.0892818421125412,\n",
       "  0.03028946742415428,\n",
       "  -0.0025380561128258705,\n",
       "  -0.0038235317915678024,\n",
       "  -0.0006306496798060834,\n",
       "  -0.00019499679910950363,\n",
       "  0.05119752883911133,\n",
       "  0.006147356703877449,\n",
       "  0.05102761089801788,\n",
       "  0.041587792336940765,\n",
       "  -0.005261062644422054,\n",
       "  -0.005028523970395327,\n",
       "  -0.005887181498110294,\n",
       "  0.000490653736051172,\n",
       "  0.010096298530697823,\n",
       "  0.03685986250638962,\n",
       "  -0.007216492667794228,\n",
       "  0.03187129646539688,\n",
       "  0.031884271651506424,\n",
       "  0.06641353666782379,\n",
       "  -0.00043469510274007916,\n",
       "  0.05217085778713226,\n",
       "  0.06948713958263397,\n",
       "  0.002162969671189785,\n",
       "  0.04597824066877365,\n",
       "  0.007319414988160133,\n",
       "  0.054881975054740906,\n",
       "  0.051692038774490356,\n",
       "  0.08633974939584732,\n",
       "  0.03521658480167389,\n",
       "  -0.0056150793097913265,\n",
       "  0.04409189522266388,\n",
       "  0.042954400181770325,\n",
       "  -0.00017498497618362308,\n",
       "  0.014381357468664646,\n",
       "  -0.00137396901845932,\n",
       "  0.02683410421013832,\n",
       "  -0.004330992698669434,\n",
       "  0.013742707669734955,\n",
       "  0.05075882002711296,\n",
       "  0.06852312386035919,\n",
       "  0.03172329068183899,\n",
       "  0.05229450389742851,\n",
       "  -0.0001607087760930881,\n",
       "  0.057407401502132416,\n",
       "  0.052565157413482666,\n",
       "  0.03626967966556549,\n",
       "  0.00016921295900829136,\n",
       "  -0.0009887318592518568,\n",
       "  0.03124147281050682,\n",
       "  0.03733697533607483,\n",
       "  0.03521575778722763,\n",
       "  0.05592234432697296,\n",
       "  -0.005752289667725563,\n",
       "  0.011874817311763763,\n",
       "  0.01661219261586666,\n",
       "  -0.0038358664605766535,\n",
       "  0.02163650467991829,\n",
       "  0.03129129484295845,\n",
       "  0.020843002945184708,\n",
       "  0.03872358798980713,\n",
       "  0.07087749987840652,\n",
       "  0.042523451149463654,\n",
       "  0.05431028828024864,\n",
       "  0.03558877483010292,\n",
       "  0.058740489184856415,\n",
       "  0.005024241749197245,\n",
       "  0.04593667387962341,\n",
       "  0.007129451725631952,\n",
       "  -0.0057195983827114105,\n",
       "  -0.0004499804344959557,\n",
       "  -0.007473712787032127,\n",
       "  0.04796687886118889,\n",
       "  -0.003566727042198181,\n",
       "  -0.00041869733831845224,\n",
       "  0.03408527746796608,\n",
       "  -0.0007606226135976613,\n",
       "  -0.00108812446705997,\n",
       "  0.04704151302576065,\n",
       "  0.09073112905025482,\n",
       "  0.056459832936525345,\n",
       "  -0.004803969990462065,\n",
       "  0.06596675515174866,\n",
       "  -0.0038816132582724094,\n",
       "  0.021005885675549507,\n",
       "  0.07048386335372925,\n",
       "  0.05493931099772453,\n",
       "  -0.0055740028619766235,\n",
       "  0.0006131647969596088,\n",
       "  0.022290725260972977,\n",
       "  0.027276653796434402,\n",
       "  0.04689677059650421,\n",
       "  0.02784029394388199,\n",
       "  0.051934242248535156,\n",
       "  -0.0050146859139204025,\n",
       "  0.03306236118078232,\n",
       "  -0.005024913232773542,\n",
       "  0.059708576649427414,\n",
       "  0.0016104684909805655,\n",
       "  0.019069580361247063,\n",
       "  0.03613463044166565,\n",
       "  0.04822074621915817,\n",
       "  0.05053456500172615,\n",
       "  0.03393399342894554,\n",
       "  -0.005452307406812906,\n",
       "  -0.004836945794522762,\n",
       "  -7.578753866255283e-05,\n",
       "  0.02862902730703354,\n",
       "  0.0351598858833313,\n",
       "  0.0016919816844165325,\n",
       "  0.008088357746601105,\n",
       "  -0.00010429671965539455,\n",
       "  0.0016738357953727245,\n",
       "  -0.001162933767773211,\n",
       "  -0.00010214326903223991,\n",
       "  0.011846504174172878,\n",
       "  -7.71248887758702e-05,\n",
       "  0.04783817380666733,\n",
       "  0.03264345973730087,\n",
       "  0.0007039115880616009,\n",
       "  0.034962743520736694,\n",
       "  0.010457571595907211,\n",
       "  0.013090064749121666,\n",
       "  -0.005461764521896839,\n",
       "  -0.001839322503656149,\n",
       "  -0.0006976305157877505,\n",
       "  0.09929785132408142,\n",
       "  0.049184903502464294,\n",
       "  -0.0002202750474680215,\n",
       "  0.03200447931885719,\n",
       "  -0.004246987402439117,\n",
       "  -0.0038959747180342674,\n",
       "  -0.004624335095286369,\n",
       "  0.00034279521787539124,\n",
       "  0.050034623593091965,\n",
       "  -0.004420245066285133,\n",
       "  -0.004311609081923962,\n",
       "  -0.0030466471798717976,\n",
       "  -0.0062310704961419106,\n",
       "  0.0007257853867486119,\n",
       "  0.03566316142678261,\n",
       "  -0.004336758516728878,\n",
       "  -0.004363297019153833,\n",
       "  0.021134139969944954,\n",
       "  -0.006096436642110348,\n",
       "  0.03366907313466072,\n",
       "  0.05955108255147934,\n",
       "  0.04984062910079956,\n",
       "  0.041130878031253815,\n",
       "  -0.006769636645913124,\n",
       "  0.03139572590589523,\n",
       "  -0.004550052806735039,\n",
       "  0.06125619262456894,\n",
       "  0.02936132624745369,\n",
       "  -0.0011409972794353962,\n",
       "  0.06082192808389664,\n",
       "  0.026916375383734703,\n",
       "  0.0038707400672137737,\n",
       "  0.043754592537879944,\n",
       "  0.06095118820667267,\n",
       "  0.0011597230331972241,\n",
       "  0.00027846096782013774,\n",
       "  0.050671059638261795,\n",
       "  -0.0008117308607324958,\n",
       "  -0.004958327393978834,\n",
       "  0.012825323268771172,\n",
       "  0.05848955735564232,\n",
       "  0.05015687644481659,\n",
       "  0.03217324987053871]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_list_dict['82837252']['objects']['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "training_list = []\n",
    "for i in train_list_dict.keys():\n",
    "    for x in train_list_dict[i]['objects'].keys():\n",
    "      training_list.append(train_list_dict[i]['objects'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cU_KF43l9UcS"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle('funsd/funsd_bert_list_train.pkl')\n",
    "df_test = pd.read_pickle('funsd/funsd_bert_list_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "WB8gHoFVObjC",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7411, 6)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "sb1Q5N6LGK7z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Yk1wrbvciXrg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>box</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>relations</th>\n",
       "      <th>gcn_bert_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[105, 134, 158, 149]</td>\n",
       "      <td>question</td>\n",
       "      <td>Location</td>\n",
       "      <td>{'0': {'name': 'answer', 'id': 8473, 'object':...</td>\n",
       "      <td>[-0.003128426382318139, 0.013897834345698357, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[425, 130, 475, 145]</td>\n",
       "      <td>question</td>\n",
       "      <td>Division</td>\n",
       "      <td>{'0': {'name': 'answer', 'id': 8474, 'object':...</td>\n",
       "      <td>[-0.005620114505290985, 0.026954488828778267, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[432, 226, 502, 243]</td>\n",
       "      <td>header</td>\n",
       "      <td>Invitations:</td>\n",
       "      <td>{'0': {'name': 'question', 'id': 8475, 'object...</td>\n",
       "      <td>[-0.005865470506250858, 0.031202778220176697, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[103, 254, 139, 269]</td>\n",
       "      <td>question</td>\n",
       "      <td>Mugs</td>\n",
       "      <td>{'0': {'name': 'header', 'id': 8478, 'object':...</td>\n",
       "      <td>[-0.00615231366828084, 0.027706364169716835, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[105, 300, 157, 315]</td>\n",
       "      <td>question</td>\n",
       "      <td>Posters</td>\n",
       "      <td>{'0': {'name': 'header', 'id': 8480, 'object':...</td>\n",
       "      <td>[-0.005726724863052368, 0.0267567727714777, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   box  category          text  \\\n",
       "0   0  [105, 134, 158, 149]  question      Location   \n",
       "1   1  [425, 130, 475, 145]  question      Division   \n",
       "2   2  [432, 226, 502, 243]    header  Invitations:   \n",
       "3   3  [103, 254, 139, 269]  question          Mugs   \n",
       "4   4  [105, 300, 157, 315]  question       Posters   \n",
       "\n",
       "                                           relations  \\\n",
       "0  {'0': {'name': 'answer', 'id': 8473, 'object':...   \n",
       "1  {'0': {'name': 'answer', 'id': 8474, 'object':...   \n",
       "2  {'0': {'name': 'question', 'id': 8475, 'object...   \n",
       "3  {'0': {'name': 'header', 'id': 8478, 'object':...   \n",
       "4  {'0': {'name': 'header', 'id': 8480, 'object':...   \n",
       "\n",
       "                                      gcn_bert_large  \n",
       "0  [-0.003128426382318139, 0.013897834345698357, ...  \n",
       "1  [-0.005620114505290985, 0.026954488828778267, ...  \n",
       "2  [-0.005865470506250858, 0.031202778220176697, ...  \n",
       "3  [-0.00615231366828084, 0.027706364169716835, -...  \n",
       "4  [-0.005726724863052368, 0.0267567727714777, -0...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'box', 'category', 'text', 'relations', 'gcn_bert_large'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list_dict['92091873']['objects']['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "baSmeDdIEadM"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['label', 'near_visual_feature', 'gcn_near_char_density', 'gcn_near_char_number', 'level1_parse_emb', 'level2_parse_emb', 'gcn_near_token_density', 'density', 'visual_feature', 'gcn_bert_predicted'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m new_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnear_visual_feature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m\t\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgcn_near_char_density\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m\t\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgcn_near_char_number\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlevel1_parse_emb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlevel2_parse_emb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgcn_near_token_density\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdensity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvisual_feature\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgcn_bert_predicted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/pandas/core/indexes/base.py:6133\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6133\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['label', 'near_visual_feature', 'gcn_near_char_density', 'gcn_near_char_number', 'level1_parse_emb', 'level2_parse_emb', 'gcn_near_token_density', 'density', 'visual_feature', 'gcn_bert_predicted'] not in index\""
     ]
    }
   ],
   "source": [
    "new_df = df_train[['text', 'label','near_visual_feature',\t'gcn_near_char_density',\t'gcn_near_char_number',\n",
    "                   'level1_parse_emb','level2_parse_emb','gcn_near_token_density','density','visual_feature','gcn_bert_predicted']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qX1g2eqC0s4I"
   },
   "outputs": [],
   "source": [
    "new_df_test = df_test[['text', 'label','near_visual_feature',\t'gcn_near_char_density',\t'gcn_near_char_number',\n",
    "                   'level1_parse_emb','level2_parse_emb','gcn_near_token_density','density','visual_feature','gcn_bert_predicted']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbiQjAgdSqhn"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nvXxpfNCGER2"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 100\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = TRAIN_BATCH_SIZE*2\n",
    "# EPOCHS = 1\n",
    "LEARNING_RATE = 2e-05\n",
    "# Change the pre-trained bert model\n",
    "#tokenizer = BertTokenizer.from_pretrained('roberta-base') #Cased "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3vWRDemOGxJD"
   },
   "outputs": [],
   "source": [
    "class SentimentData(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.text\n",
    "        self.targets = self.data.label\n",
    "        self.gcn_visual_feature = dataframe.near_visual_feature\n",
    "        self.visual_feature = dataframe.visual_feature\n",
    "        self.gcn_bert_base = dataframe.gcn_bert_predicted\n",
    "        self.parsing1 = dataframe.level1_parse_emb\n",
    "        self.parsing2 = dataframe.level2_parse_emb\n",
    "        self.char_density = dataframe.gcn_near_char_density\n",
    "        self.char_number = dataframe.gcn_near_char_number\n",
    "        self.density = dataframe.density\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float),\n",
    "            'density': torch.tensor(self.density[index],dtype=torch.float),\n",
    "            'gcn_bert_base': torch.tensor(self.gcn_bert_base[index],dtype=torch.float),\n",
    "            'char_density': torch.tensor(self.char_density[index],dtype=torch.float),\n",
    "            'char_number': torch.tensor(self.char_number[index],dtype=torch.float),\n",
    "            'visual_feature': torch.tensor(self.visual_feature[index],dtype=torch.float),\n",
    "            'parsing1': torch.tensor(self.parsing1[index],dtype=torch.float),\n",
    "            'parsing2': torch.tensor(self.parsing2[index],dtype=torch.float),\n",
    "            'gcn_visual_feature': torch.tensor(self.gcn_visual_feature[index],dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Gpe9D1QHoCd"
   },
   "outputs": [],
   "source": [
    "train_size = 1\n",
    "train_data=new_df.sample(frac=train_size,random_state=200)\n",
    "#test_data=new_df.drop(train_data.index).reset_index(drop=True)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(new_df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
    "print(\"TEST Dataset: {}\".format(new_df_test.shape))\n",
    "\n",
    "training_set = SentimentData(train_data, tokenizer, MAX_LEN)\n",
    "#testing_set = SentimentData(test_data, tokenizer, MAX_LEN)\n",
    "test_set = SentimentData(new_df_test,tokenizer,MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c1tInLk2Eadt"
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "#testing_loader = DataLoader(testing_set, **test_params)\n",
    "vali_loader = DataLoader(test_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jF12YgfxSwEr"
   },
   "source": [
    "## Define the proposed classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMqQTafXEaei"
   },
   "outputs": [],
   "source": [
    "class RobertaClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RobertaClass, self).__init__()\n",
    "        #bert-base-cased 768\n",
    "        #bert-large-cased bert-large-uncased 1024\n",
    "        #roberta-base-cased 768\n",
    "        #biobert\n",
    "\n",
    "        self.l1 = AutoModel.from_pretrained(\"bert-base-uncased\")# BERT large\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.hidden_cls = torch.nn.Linear(768,768)\n",
    "        self.hidden_parsing = torch.nn.Linear(768,768)\n",
    "        self.hidden_den = torch.nn.Linear(768,768)\n",
    "        self.hidden_vis = torch.nn.Linear(768,768)\n",
    "        self.hidden_vis_pro = torch.nn.Linear(768,768)\n",
    "        self.hidden_all = torch.nn.Linear(768*2,768*2)\n",
    "        self.before_classifier = torch.nn.Linear(768*2,128)\n",
    "\\\n",
    "        self.pooling = torch.nn.MaxPool2d((2,1), stride=None)\n",
    "        self.classifier = torch.nn.Linear(128, 4)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, char_density,char_number,visual_feature,bert_cls,parsing1,parsing2,visual):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "\n",
    "        # BERT 768 BERT / large 1024\n",
    "        \n",
    "        # set different hidden layer, number of hidden units, regularization methods including bn and dropout\n",
    "        \n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.Tanh()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "\n",
    "        pooler = torch.cat((pooler.unsqueeze(1),bert_cls.unsqueeze(1)),1)\n",
    "        pooler = self.pooling(pooler).squeeze(1)\n",
    "        pooler = self.hidden_cls(pooler)\n",
    "        pooler = torch.nn.Tanh()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "\n",
    "        visual = self.hidden_vis_pro(visual)\n",
    "        visual = torch.nn.Tanh()(visual)\n",
    "        visual = self.dropout(visual)\n",
    "\n",
    "        visual = torch.cat((visual.unsqueeze(1),visual_feature.unsqueeze(1)),1)\n",
    "        visual = self.pooling(visual).squeeze(1)\n",
    "        visual = self.hidden_vis(visual)\n",
    "        visual = torch.nn.Tanh()(visual)\n",
    "        visual = self.dropout(visual)\n",
    "\n",
    "        pooler = torch.cat((pooler,visual),1)\n",
    "        pooler = self.hidden_all(pooler)\n",
    "        pooler = torch.nn.Tanh()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "\n",
    "        pooler = self.before_classifier(pooler)\n",
    "        pooler = torch.nn.Tanh()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZ55mIPZIkp_"
   },
   "outputs": [],
   "source": [
    "model = RobertaClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XBJjGKdS2b8"
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XYZ7YuJ5InOS"
   },
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=1e-05) # change learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPhA2V3iIpzN"
   },
   "outputs": [],
   "source": [
    "def calcuate_accuracy(preds, targets):\n",
    "    n_correct = (preds==targets).sum().item()\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhqvtY2SIup7"
   },
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the distilbert model\n",
    "\n",
    "def train(epoch):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    output = []\n",
    "    model.train()\n",
    "    for _,data in tqdm(enumerate(training_loader, 0)):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "        visual_feature = data['visual_feature'].to(device, dtype = torch.float)\n",
    "        gcn_visual_feature = data['gcn_visual_feature'].to(device, dtype = torch.float)\n",
    "        gcn_bert_base = data['gcn_bert_base'].to(device, dtype = torch.float)\n",
    "        parsing1 = data['parsing1'].to(device, dtype = torch.float)\n",
    "        parsing2 = data['parsing2'].to(device, dtype = torch.float)\n",
    "        char_density = data['char_density'].to(device, dtype = torch.float)\n",
    "        char_number = data['char_number'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = model(ids, mask, token_type_ids,char_density,char_number,gcn_visual_feature,gcn_bert_base,parsing1,parsing2,visual_feature)\n",
    "\n",
    "        loss = loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        n_correct += calcuate_accuracy(big_idx, targets)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "        \n",
    "        if _%5000==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            accu_step = (n_correct*100)/nb_tr_examples \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # # When using GPU\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ecydbX_S6Lg"
   },
   "source": [
    "## Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFiNcy16JLwt"
   },
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    model.eval()\n",
    "    n_correct = 0; n_wrong = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n",
    "    output_list = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            char_den = data['char_density'].to(device, dtype = torch.float)\n",
    "            density = data['density'].to(device, dtype = torch.float)\n",
    "            visual_feature = data['visual_feature'].to(device, dtype = torch.float)\n",
    "            gcn_bert_base = data['gcn_bert_base'].to(device, dtype = torch.float)\n",
    "            parsing1 = data['parsing1'].to(device, dtype = torch.float)\n",
    "            parsing2 = data['parsing2'].to(device, dtype = torch.float)\n",
    "            char_density = data['char_density'].to(device, dtype = torch.float)\n",
    "            char_number = data['char_number'].to(device, dtype = torch.float)\n",
    "            token_density = data['token_density'].to(device, dtype = torch.float)\n",
    "            token_number = data['token_number'].to(device, dtype = torch.float)\n",
    "\n",
    "\n",
    "            outputs = model(ids, mask, token_type_ids,visual_feature,char_density,char_number,token_density,token_number).squeeze()\n",
    "            loss = loss_function(outputs, targets)\n",
    "            tr_loss += loss.item()\n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            output_list = output_list + list(big_idx)\n",
    "            n_correct += calcuate_accuracy(big_idx, targets)\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=targets.size(0)\n",
    "            \n",
    "            \n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
    "    \n",
    "    return epoch_accu,output_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-SBT2HeR_5t"
   },
   "outputs": [],
   "source": [
    "acc,pre_list = valid(model, vali_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_8lSc-jf7bU"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_qD3e22vE7My"
   },
   "outputs": [],
   "source": [
    "class SentimentData_test(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.text\n",
    "        self.targets = self.data.label\n",
    "        self.gcn_visual_feature = dataframe.near_visual_feature\n",
    "        self.visual_feature = dataframe.visual_feature\n",
    "        self.gcn_bert_base = dataframe.gcn_bert_predicted\n",
    "        self.parsing1 = dataframe.level1_parse_emb\n",
    "        self.parsing2 = dataframe.level2_parse_emb\n",
    "        self.char_density = dataframe.gcn_near_char_density\n",
    "        self.char_number = dataframe.gcn_near_char_number\n",
    "        self.density = dataframe.density\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float),\n",
    "            'density': torch.tensor(self.density[index],dtype=torch.float),\n",
    "            'gcn_bert_base': torch.tensor(self.gcn_bert_base[index],dtype=torch.float),\n",
    "            'char_density': torch.tensor(self.char_density[index],dtype=torch.float),\n",
    "            'char_number': torch.tensor(self.char_number[index],dtype=torch.float),\n",
    "            'visual_feature': torch.tensor(self.visual_feature[index],dtype=torch.float),\n",
    "            'parsing1': torch.tensor(self.parsing1[index],dtype=torch.float),\n",
    "            'parsing2': torch.tensor(self.parsing2[index],dtype=torch.float),\n",
    "            'gcn_visual_feature': torch.tensor(self.gcn_visual_feature[index],dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMRN5w3RXjqB"
   },
   "source": [
    "### load the test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zaw4D5UKFe-Z"
   },
   "outputs": [],
   "source": [
    "new_df_true_test = new_df_test[['text', 'label','near_visual_feature',\t'gcn_near_char_density',\t'gcn_near_char_number',\n",
    "                   'level1_parse_emb','level2_parse_emb','gcn_bert_predicted','visual_feature','gcn_near_token_density','density']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B0kUqjR1Fhb6"
   },
   "outputs": [],
   "source": [
    "test = SentimentData_test(new_df_true_test,tokenizer, MAX_LEN)\n",
    "testing_loader = DataLoader(test, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IetKrn_SY-OT"
   },
   "outputs": [],
   "source": [
    "def test_label_generator(model, testing_loader):\n",
    "    model.eval()\n",
    "    n_correct = 0; n_wrong = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n",
    "    output_list = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            visual_feature = data['visual_feature'].to(device, dtype = torch.float)\n",
    "            gcn_visual_feature = data['gcn_visual_feature'].to(device, dtype = torch.float)\n",
    "            gcn_bert_base = data['gcn_bert_base'].to(device, dtype = torch.float)\n",
    "            parsing1 = data['parsing1'].to(device, dtype = torch.float)\n",
    "            parsing2 = data['parsing2'].to(device, dtype = torch.float)\n",
    "            char_density = data['char_density'].to(device, dtype = torch.float)\n",
    "            char_number = data['char_number'].to(device, dtype = torch.float)\n",
    "\n",
    "            outputs = model(ids, mask, token_type_ids,char_density,char_number,gcn_visual_feature,gcn_bert_base,parsing1,parsing2,visual_feature).squeeze()\n",
    "\n",
    "            \n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            output_list = output_list + list(big_idx)\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            \n",
    "    return output_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZTbJkdtWoZZ"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 4\n",
    "for epoch in range(EPOCHS):\n",
    "  train(epoch)\n",
    "  output = test_label_generator(model, testing_loader)\n",
    "  q = []\n",
    "  for p in output:\n",
    "    q.append(p.cpu().numpy().tolist())\n",
    "  p = new_df_test['label'].tolist()\n",
    "  from sklearn.metrics import classification_report, confusion_matrix\n",
    "  report = classification_report(p,q, digits=4)\n",
    "  print(report)  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
