{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQpJTV7RSVZW",
    "tags": []
   },
   "source": [
    "## Environment Setup\n",
    "Import key libraries and working envorinments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a-GlywkSFegL"
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "979OUro5Eac3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing the libraries needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import transformers\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "#from transformers.configuration_bert import BertConfig\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "I9sVem7yb4MN"
   },
   "outputs": [],
   "source": [
    "# !pip install -U -q PyDrive\n",
    "# from pydrive.auth import GoogleAuth\n",
    "# from pydrive.drive import GoogleDrive\n",
    "# from google.colab import auth\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "# import pandas as pd\n",
    "\n",
    "# # Authenticate\n",
    "# drive = None\n",
    "# def authenticate():\n",
    "#   global drive\n",
    "  \n",
    "#   auth.authenticate_user()\n",
    "#   gauth = GoogleAuth()\n",
    "#   gauth.credentials = GoogleCredentials.get_application_default()\n",
    "#   drive = GoogleDrive(gauth)\n",
    "\n",
    "# #Download files\n",
    "# def downloadFiles(fileIds):\n",
    "#   authenticate()\n",
    "  \n",
    "#   for fileId in fileIds:    \n",
    "    \n",
    "#     downloaded = drive.CreateFile({\"id\": fileId[1]})\n",
    "#     downloaded.GetContentFile(fileId[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Sd2-rgBQp269"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B7TWqvbTppX_"
   },
   "source": [
    "##Get Training and Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pb5R9jPabbKD"
   },
   "outputs": [],
   "source": [
    "# #Do not downloading training and validation dataset at same time \n",
    "# try:\n",
    "#   _ = open(\"testing_dataset.pkl\", \"r\")\n",
    "# except:\n",
    "#   downloadFiles([[\"testing_dataset.pkl\", \"1fktW64hxcjCXreMTv_2pAxSe4Nt083z3\"]])\n",
    "\n",
    "# try:\n",
    "#   _ = open(\"training_dataset.pkl\", \"r\")\n",
    "# except:\n",
    "#   downloadFiles([[\"training_dataset.pkl\", \"1td4mF-QxrwKF125xR5DWflGqcwn0z1LP\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "t_0-NGiEViK1"
   },
   "outputs": [],
   "source": [
    "# #Download file if not existing\n",
    "# try:\n",
    "#   _ = open(\"visual_train.pkl\", \"r\")\n",
    "# except:\n",
    "#   downloadFiles([[\"visual_train.pkl\", \"1-1iI14bgFX8QbhA1uPjI7VA6kfIhPhxM\"]])\n",
    "\n",
    "# try:\n",
    "#   _ = open(\"visual_test.pkl\", \"r\")\n",
    "# except:\n",
    "#   downloadFiles([[\"visual_test.pkl\", \"1sEVX0nd09MfvgwrPc4KxWrClDIJpQOoz\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"training_dataset_pc_relation.pkl\", \"rb\") as fp:\n",
    "    train_pc_dict = pickle.load(fp) \n",
    " \n",
    "with open(\"testing_dataset_pc_relation.pkl\", \"rb\") as fp:\n",
    "    test_pc_dict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 149)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pc_dict.keys()), len(train_dw_dict.keys()),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'box', 'category', 'text', 'relations', 'bert_large_emb', 'gcn_bert_large'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pc_dict['92091873']['objects']['0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pc_dict['92091873']['objects']['0']['bert_large_emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pc_dict['92091873']['objects']['0']['gcn_bert_large'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"training_dataset.pkl\", \"rb\") as fp:\n",
    "    train_dw_dict = pickle.load(fp) \n",
    " \n",
    "with open(\"testing_dataset.pkl\", \"rb\") as fp:\n",
    "    test_dw_dict = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'box', 'category', 'text', 'relations', 'gap', 'text_density', 'text_number', 'char_density', 'char_number', 'parsing_level1', 'parsing_level2', 'near_gap', 'gcn_token_number'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dw_dict['92091873']['objects']['0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "img_ls = os.listdir('../data/training_data/images')\n",
    "visual_features_train_list = []\n",
    "for i in range(len(img_ls)):\n",
    "      file_name = img_ls[i][:-4]\n",
    "      path = '../funsd/visual_feature/object_train/'+file_name+'.json'\n",
    "      # print(path)\n",
    "      with open(path,'r') as file_object:\n",
    "        visual_features = json.load(file_object)\n",
    "        visual_features_train_list.append(visual_features)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 2048\n"
     ]
    }
   ],
   "source": [
    "print(len(visual_features_train_list), len(visual_features_train_list[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(visual_features_train_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, json\n",
    "img_ls = os.listdir('../data/testing_data/images')\n",
    "visual_features_test_list = []\n",
    "for i in range(len(img_ls)):\n",
    "      file_name = img_ls[i][:-4]\n",
    "      path = '../funsd/visual_feature/object_test/'+file_name+'.json'\n",
    "      # print(path)\n",
    "      with open(path,'r') as file_object:\n",
    "        visual_features = json.load(file_object)\n",
    "        visual_features_test_list.append(visual_features)        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 2048\n"
     ]
    }
   ],
   "source": [
    "print(len(visual_features_test_list), len(visual_features_test_list[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(visual_features_test_list[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k,p in enumerate(train_dw_dict):\n",
    "    for i, j in enumerate(train_dw_dict[p]['objects']):\n",
    "        train_dw_dict[p]['objects'][j]['visual_embeddings'] = visual_features_train_list[k][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'box', 'category', 'text', 'relations', 'gap', 'text_density', 'text_number', 'char_density', 'char_number', 'parsing_level1', 'parsing_level2', 'near_gap', 'gcn_token_number', 'visual_embeddings'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dw_dict['92091873']['objects']['0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dw_dict['92091873']['objects']['0']['visual_embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k,p in enumerate(test_dw_dict):\n",
    "    for i, j in enumerate(test_dw_dict[p]['objects']):\n",
    "        test_dw_dict[p]['objects'][j]['visual_embeddings'] = visual_features_test_list[k][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'box', 'category', 'text', 'relations', 'gap', 'text_density', 'text_number', 'char_density', 'char_number', 'parsing_level1', 'parsing_level2', 'near_gap', 'gcn_token_number', 'visual_embeddings'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dw_dict['82837252']['objects']['0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dw_dict['82837252']['objects']['0']['visual_embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'box', 'category', 'text', 'relations', 'gap', 'text_density', 'text_number', 'char_density', 'char_number', 'parsing_level1', 'parsing_level2', 'near_gap', 'gcn_token_number', 'visual_embeddings'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dw_dict['82837252']['objects']['0'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dw_dict['82837252']['objects']['0']['gcn_token_number'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dw_dict['82837252']['objects']['0']['visual_embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qiF6LKqVuje"
   },
   "outputs": [],
   "source": [
    "# train_visual = pd.read_pickle('visual_train.pkl')\n",
    "# test_visual = pd.read_pickle('visual_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c4bGVgzk-HT-"
   },
   "outputs": [],
   "source": [
    "# print(train_visual.shape)\n",
    "# print(test_visual.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xY7KOu_6Dtzh"
   },
   "outputs": [],
   "source": [
    "# df_train = pd.read_pickle('training_dataset.pkl')\n",
    "# df_test = pd.read_pickle('testing_dataset.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4k5hCBUG-O1x"
   },
   "outputs": [],
   "source": [
    "# print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzwacY0IH7ef"
   },
   "outputs": [],
   "source": [
    "# df_train['visual_embedding'] = test_visual['visual_embedding']\n",
    "# df_test['visual_embedding'] = train_visual['visual_embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HNZW1muhZXBL"
   },
   "outputs": [],
   "source": [
    "# print(test_visual.shape)\n",
    "# print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DkpX4X0YxgK"
   },
   "outputs": [],
   "source": [
    "# test_visual.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2EV5VAOH93J"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdJi7AxkpQFr"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "df_train.head()\n",
    "density_emb_train = df_train['char_density_emb'].tolist()\n",
    "density_emb_test = df_test['char_density_emb'].tolist()\n",
    "number_emb_train = df_train['char_number_emb'].tolist()\n",
    "number_emb_test = df_test['char_number_emb'].tolist()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4GljdlwFo-IF"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "df_train = pd.read_pickle('/content/drive/MyDrive/funsd/funsd_object_gcn_visual_density_train.pkl')\n",
    "df_test = pd.read_pickle('/content/drive/MyDrive/funsd/funsd_object_gcn_visual_density_test.pkl')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wH2iQ_QspxiY"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "df_train['char_density_emb'] = density_emb_train\n",
    "df_train['char_number_emb'] = number_emb_train\n",
    "df_test['char_density_emb'] = density_emb_test\n",
    "df_test['char_number_emb'] = number_emb_test\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "sb1Q5N6LGK7z",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_dw_list = []\n",
    "for file in train_dw_dict:\n",
    "    for x in train_dw_dict[file]['objects']:\n",
    "      training_dw_list.append(train_dw_dict[file]['objects'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7411"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_dw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing_dw_list = []\n",
    "for file in test_dw_dict:\n",
    "    for x in test_dw_dict[file]['objects']:\n",
    "      testing_dw_list.append(test_dw_dict[file]['objects'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2332"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing_dw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_pc_list = []\n",
    "for file in train_pc_dict:\n",
    "    for x in train_pc_dict[file]['objects']:\n",
    "      training_pc_list.append(train_pc_dict[file]['objects'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7411"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_pc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing_pc_list = []\n",
    "for file in test_pc_dict:\n",
    "    for x in test_pc_dict[file]['objects']:\n",
    "      testing_pc_list.append(test_pc_dict[file]['objects'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2332"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing_pc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "df_dw_train = DataFrame(training_dw_list)\n",
    "df_dw_test = DataFrame(testing_dw_list)\n",
    "df_pc_train = DataFrame(training_pc_list)\n",
    "df_pc_test = DataFrame(testing_pc_list)\n",
    "\n",
    "# df_dw_train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7411, 15), (7411, 7))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dw_train.shape, df_pc_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2332, 15), (2332, 7))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dw_test.shape, df_pc_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'box', 'category', 'text', 'relations', 'gap', 'text_density',\n",
       "       'text_number', 'char_density', 'char_number', 'parsing_level1',\n",
       "       'parsing_level2', 'near_gap', 'gcn_token_number', 'visual_embeddings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dw_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'box', 'category', 'text', 'relations', 'bert_large_emb',\n",
       "       'gcn_bert_large'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pc_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7411, 15), (7411, 3))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dw_train.shape, df_pc_train[['text','bert_large_emb','gcn_bert_large']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>box</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>relations</th>\n",
       "      <th>bert_large_emb</th>\n",
       "      <th>gcn_bert_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[105, 134, 158, 149]</td>\n",
       "      <td>question</td>\n",
       "      <td>Location</td>\n",
       "      <td>{'0': {'id': 0, 'object': 1}, '1': {'id': 1, '...</td>\n",
       "      <td>[-0.6775245666503906, -0.5909585952758789, -0....</td>\n",
       "      <td>[-0.00082297134, -0.00088567723, 0.046493772, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[425, 130, 475, 145]</td>\n",
       "      <td>question</td>\n",
       "      <td>Division</td>\n",
       "      <td>{'0': {'id': 70, 'object': 0}, '1': {'id': 71,...</td>\n",
       "      <td>[-0.24348104000091553, 0.060652412474155426, -...</td>\n",
       "      <td>[-0.00082297134, -0.00088567723, 0.046493772, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[432, 226, 502, 243]</td>\n",
       "      <td>header</td>\n",
       "      <td>Invitations:</td>\n",
       "      <td>{'0': {'id': 140, 'object': 0}, '1': {'id': 14...</td>\n",
       "      <td>[-0.5478321313858032, 0.030162598937749863, 0....</td>\n",
       "      <td>[-0.00082297134, -0.00088567723, 0.046493772, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[103, 254, 139, 269]</td>\n",
       "      <td>question</td>\n",
       "      <td>Mugs</td>\n",
       "      <td>{'0': {'id': 210, 'object': 0}, '1': {'id': 21...</td>\n",
       "      <td>[-0.26809656620025635, 0.20610269904136658, -0...</td>\n",
       "      <td>[-0.00082297134, -0.00088567723, 0.046493772, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[105, 300, 157, 315]</td>\n",
       "      <td>question</td>\n",
       "      <td>Posters</td>\n",
       "      <td>{'0': {'id': 280, 'object': 0}, '1': {'id': 28...</td>\n",
       "      <td>[-0.26464468240737915, -0.2642456889152527, -0...</td>\n",
       "      <td>[-0.00082297134, -0.00088567723, 0.046493772, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   box  category          text  \\\n",
       "0   0  [105, 134, 158, 149]  question      Location   \n",
       "1   1  [425, 130, 475, 145]  question      Division   \n",
       "2   2  [432, 226, 502, 243]    header  Invitations:   \n",
       "3   3  [103, 254, 139, 269]  question          Mugs   \n",
       "4   4  [105, 300, 157, 315]  question       Posters   \n",
       "\n",
       "                                           relations  \\\n",
       "0  {'0': {'id': 0, 'object': 1}, '1': {'id': 1, '...   \n",
       "1  {'0': {'id': 70, 'object': 0}, '1': {'id': 71,...   \n",
       "2  {'0': {'id': 140, 'object': 0}, '1': {'id': 14...   \n",
       "3  {'0': {'id': 210, 'object': 0}, '1': {'id': 21...   \n",
       "4  {'0': {'id': 280, 'object': 0}, '1': {'id': 28...   \n",
       "\n",
       "                                      bert_large_emb  \\\n",
       "0  [-0.6775245666503906, -0.5909585952758789, -0....   \n",
       "1  [-0.24348104000091553, 0.060652412474155426, -...   \n",
       "2  [-0.5478321313858032, 0.030162598937749863, 0....   \n",
       "3  [-0.26809656620025635, 0.20610269904136658, -0...   \n",
       "4  [-0.26464468240737915, -0.2642456889152527, -0...   \n",
       "\n",
       "                                      gcn_bert_large  \n",
       "0  [-0.00082297134, -0.00088567723, 0.046493772, ...  \n",
       "1  [-0.00082297134, -0.00088567723, 0.046493772, ...  \n",
       "2  [-0.00082297134, -0.00088567723, 0.046493772, ...  \n",
       "3  [-0.00082297134, -0.00088567723, 0.046493772, ...  \n",
       "4  [-0.00082297134, -0.00088567723, 0.046493772, ...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pc_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_dw_train, df_pc_train[['id','bert_large_emb','gcn_bert_large']]\\\n",
    "                    , on=['id','id'], how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7411, 17)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>box</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>relations</th>\n",
       "      <th>gap</th>\n",
       "      <th>text_density</th>\n",
       "      <th>text_number</th>\n",
       "      <th>char_density</th>\n",
       "      <th>char_number</th>\n",
       "      <th>parsing_level1</th>\n",
       "      <th>parsing_level2</th>\n",
       "      <th>near_gap</th>\n",
       "      <th>gcn_token_number</th>\n",
       "      <th>visual_embeddings</th>\n",
       "      <th>bert_large_emb</th>\n",
       "      <th>gcn_bert_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[105, 134, 158, 149]</td>\n",
       "      <td>question</td>\n",
       "      <td>Location</td>\n",
       "      <td>{'0': {'id': 0, 'object': 1}, '1': {'id': 1, '...</td>\n",
       "      <td>{'1': 267, '2': 274, '3': 105, '4': 151, '5': ...</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010063</td>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'26': 17, '42': 12}</td>\n",
       "      <td>[-0.03008558, -0.041219972, -0.21079858, -0.04...</td>\n",
       "      <td>[0.0, 0.5288188457489014, 3.1429412364959717, ...</td>\n",
       "      <td>[-0.6775245666503906, -0.5909585952758789, -0....</td>\n",
       "      <td>[-0.00082297134, -0.00088567723, 0.046493772, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[425, 130, 475, 145]</td>\n",
       "      <td>question</td>\n",
       "      <td>Division</td>\n",
       "      <td>{'0': {'id': 70, 'object': 0}, '1': {'id': 71,...</td>\n",
       "      <td>{'0': 267, '2': 81, '3': 286, '4': 268, '5': 2...</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'38': 13, '44': 13}</td>\n",
       "      <td>[-0.030569917, -0.041657943, -0.20294446, -0.0...</td>\n",
       "      <td>[0.0, 0.40805140137672424, 3.3653852939605713,...</td>\n",
       "      <td>[-0.24348104000091553, 0.060652412474155426, -...</td>\n",
       "      <td>[-0.00082297134, -0.00088567723, 0.046493772, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[432, 226, 502, 243]</td>\n",
       "      <td>header</td>\n",
       "      <td>Invitations:</td>\n",
       "      <td>{'0': {'id': 140, 'object': 0}, '1': {'id': 14...</td>\n",
       "      <td>{'0': 274, '1': 81, '3': 293, '4': 275, '5': 2...</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>12</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'11': 10, '47': 5}</td>\n",
       "      <td>[-0.03380406, -0.044938385, -0.16522531, -0.04...</td>\n",
       "      <td>[0.0, 0.1519727110862732, 0.8420601487159729, ...</td>\n",
       "      <td>[-0.5478321313858032, 0.030162598937749863, 0....</td>\n",
       "      <td>[-0.00082297134, -0.00088567723, 0.046493772, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[103, 254, 139, 269]</td>\n",
       "      <td>question</td>\n",
       "      <td>Mugs</td>\n",
       "      <td>{'0': {'id': 210, 'object': 0}, '1': {'id': 21...</td>\n",
       "      <td>{'0': 105, '1': 286, '2': 293, '4': 31, '5': 3...</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'48': 9, '49': 0, '69': 9}</td>\n",
       "      <td>[-0.028979465, -0.040293574, -0.20505819, -0.0...</td>\n",
       "      <td>[0.0, 0.07907691597938538, 3.944286823272705, ...</td>\n",
       "      <td>[-0.26809656620025635, 0.20610269904136658, -0...</td>\n",
       "      <td>[-0.00082297134, -0.00088567723, 0.046493772, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[105, 300, 157, 315]</td>\n",
       "      <td>question</td>\n",
       "      <td>Posters</td>\n",
       "      <td>{'0': {'id': 280, 'object': 0}, '1': {'id': 28...</td>\n",
       "      <td>{'0': 151, '1': 268, '2': 275, '3': 31, '5': 2...</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'13': 9, '50': 1}</td>\n",
       "      <td>[-0.023589646, -0.038782388, -0.20685978, -0.0...</td>\n",
       "      <td>[0.0, 0.07378455251455307, 2.7909140586853027,...</td>\n",
       "      <td>[-0.26464468240737915, -0.2642456889152527, -0...</td>\n",
       "      <td>[-0.00082297134, -0.00088567723, 0.046493772, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   box  category          text  \\\n",
       "0   0  [105, 134, 158, 149]  question      Location   \n",
       "1   1  [425, 130, 475, 145]  question      Division   \n",
       "2   2  [432, 226, 502, 243]    header  Invitations:   \n",
       "3   3  [103, 254, 139, 269]  question          Mugs   \n",
       "4   4  [105, 300, 157, 315]  question       Posters   \n",
       "\n",
       "                                           relations  \\\n",
       "0  {'0': {'id': 0, 'object': 1}, '1': {'id': 1, '...   \n",
       "1  {'0': {'id': 70, 'object': 0}, '1': {'id': 71,...   \n",
       "2  {'0': {'id': 140, 'object': 0}, '1': {'id': 14...   \n",
       "3  {'0': {'id': 210, 'object': 0}, '1': {'id': 21...   \n",
       "4  {'0': {'id': 280, 'object': 0}, '1': {'id': 28...   \n",
       "\n",
       "                                                 gap  text_density  \\\n",
       "0  {'1': 267, '2': 274, '3': 105, '4': 151, '5': ...      0.001258   \n",
       "1  {'0': 267, '2': 81, '3': 286, '4': 268, '5': 2...      0.001333   \n",
       "2  {'0': 274, '1': 81, '3': 293, '4': 275, '5': 2...      0.001681   \n",
       "3  {'0': 105, '1': 286, '2': 293, '4': 31, '5': 3...      0.001852   \n",
       "4  {'0': 151, '1': 268, '2': 275, '3': 31, '5': 2...      0.001282   \n",
       "\n",
       "   text_number  char_density  char_number parsing_level1 parsing_level2  \\\n",
       "0            1      0.010063            8             []             []   \n",
       "1            1      0.010667            8             []             []   \n",
       "2            2      0.010084           12             []             []   \n",
       "3            1      0.007407            4             []             []   \n",
       "4            1      0.008974            7             []             []   \n",
       "\n",
       "                      near_gap  \\\n",
       "0         {'26': 17, '42': 12}   \n",
       "1         {'38': 13, '44': 13}   \n",
       "2          {'11': 10, '47': 5}   \n",
       "3  {'48': 9, '49': 0, '69': 9}   \n",
       "4           {'13': 9, '50': 1}   \n",
       "\n",
       "                                    gcn_token_number  \\\n",
       "0  [-0.03008558, -0.041219972, -0.21079858, -0.04...   \n",
       "1  [-0.030569917, -0.041657943, -0.20294446, -0.0...   \n",
       "2  [-0.03380406, -0.044938385, -0.16522531, -0.04...   \n",
       "3  [-0.028979465, -0.040293574, -0.20505819, -0.0...   \n",
       "4  [-0.023589646, -0.038782388, -0.20685978, -0.0...   \n",
       "\n",
       "                                   visual_embeddings  \\\n",
       "0  [0.0, 0.5288188457489014, 3.1429412364959717, ...   \n",
       "1  [0.0, 0.40805140137672424, 3.3653852939605713,...   \n",
       "2  [0.0, 0.1519727110862732, 0.8420601487159729, ...   \n",
       "3  [0.0, 0.07907691597938538, 3.944286823272705, ...   \n",
       "4  [0.0, 0.07378455251455307, 2.7909140586853027,...   \n",
       "\n",
       "                                      bert_large_emb  \\\n",
       "0  [-0.6775245666503906, -0.5909585952758789, -0....   \n",
       "1  [-0.24348104000091553, 0.060652412474155426, -...   \n",
       "2  [-0.5478321313858032, 0.030162598937749863, 0....   \n",
       "3  [-0.26809656620025635, 0.20610269904136658, -0...   \n",
       "4  [-0.26464468240737915, -0.2642456889152527, -0...   \n",
       "\n",
       "                                      gcn_bert_large  \n",
       "0  [-0.00082297134, -0.00088567723, 0.046493772, ...  \n",
       "1  [-0.00082297134, -0.00088567723, 0.046493772, ...  \n",
       "2  [-0.00082297134, -0.00088567723, 0.046493772, ...  \n",
       "3  [-0.00082297134, -0.00088567723, 0.046493772, ...  \n",
       "4  [-0.00082297134, -0.00088567723, 0.046493772, ...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "box                  0\n",
       "category             0\n",
       "text                 0\n",
       "relations            0\n",
       "gap                  0\n",
       "text_density         0\n",
       "text_number          0\n",
       "char_density         0\n",
       "char_number          0\n",
       "parsing_level1       0\n",
       "parsing_level2       0\n",
       "near_gap             0\n",
       "gcn_token_number     0\n",
       "visual_embeddings    0\n",
       "bert_large_emb       0\n",
       "gcn_bert_large       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     int64\n",
       "box                   object\n",
       "category              object\n",
       "text                  object\n",
       "relations             object\n",
       "gap                   object\n",
       "text_density         float64\n",
       "text_number            int64\n",
       "char_density         float64\n",
       "char_number            int64\n",
       "parsing_level1        object\n",
       "parsing_level2        object\n",
       "near_gap              object\n",
       "gcn_token_number      object\n",
       "visual_embeddings     object\n",
       "bert_large_emb        object\n",
       "gcn_bert_large        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                                   0\n",
       "box                                               [105, 134, 158, 149]\n",
       "category                                                      question\n",
       "text                                                          Location\n",
       "relations            {'0': {'id': 0, 'object': 1}, '1': {'id': 1, '...\n",
       "gap                  {'1': 267, '2': 274, '3': 105, '4': 151, '5': ...\n",
       "text_density                                                  0.001258\n",
       "text_number                                                          1\n",
       "char_density                                                  0.010063\n",
       "char_number                                                          8\n",
       "parsing_level1                                                      []\n",
       "parsing_level2                                                      []\n",
       "near_gap                                          {'26': 17, '42': 12}\n",
       "gcn_token_number     [-0.03008558, -0.041219972, -0.21079858, -0.04...\n",
       "visual_embeddings    [0.0, 0.5288188457489014, 3.1429412364959717, ...\n",
       "bert_large_emb       [-0.6775245666503906, -0.5909585952758789, -0....\n",
       "gcn_bert_large       [-0.00082297134, -0.00088567723, 0.046493772, ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train['gcn_token_number'].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train['visual_embeddings'].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train['bert_large_emb'].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train['gcn_bert_large'].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_train['bert_large_emb'] = np.asarray(df_train['bert_large_emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df_test = pd.merge(df_dw_test, df_pc_test[['text','bert_large_emb','gcn_bert_large']], on='text', how='inner') \n",
    "\n",
    "\n",
    "df_test = pd.merge(df_dw_test, df_pc_test[['id','bert_large_emb','gcn_bert_large']]\\\n",
    "                    , on=['id','id'], how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2332, 17)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>box</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>relations</th>\n",
       "      <th>gap</th>\n",
       "      <th>text_density</th>\n",
       "      <th>text_number</th>\n",
       "      <th>char_density</th>\n",
       "      <th>char_number</th>\n",
       "      <th>parsing_level1</th>\n",
       "      <th>parsing_level2</th>\n",
       "      <th>near_gap</th>\n",
       "      <th>gcn_token_number</th>\n",
       "      <th>visual_embeddings</th>\n",
       "      <th>bert_large_emb</th>\n",
       "      <th>gcn_bert_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7412</td>\n",
       "      <td>[140, 186, 179, 200]</td>\n",
       "      <td>question</td>\n",
       "      <td>DATE:</td>\n",
       "      <td>{'0': {'id': 0, 'object': 7413}, '1': {'id': 1...</td>\n",
       "      <td>{'1': 77, '2': 402, '3': 88, '4': 26, '5': 493...</td>\n",
       "      <td>0.003663</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009158</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'9': 10, '13': 15}</td>\n",
       "      <td>[-0.026612815, -0.042800277, -0.17022753, -0.0...</td>\n",
       "      <td>[0.0, 1.0358710289001465, 4.277202606201172, 0...</td>\n",
       "      <td>[-0.8346639275550842, -0.044609859585762024, 0...</td>\n",
       "      <td>[-0.0009340879, -0.000552057, 0.047308944, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7413</td>\n",
       "      <td>[256, 186, 292, 201]</td>\n",
       "      <td>question</td>\n",
       "      <td>TIME:</td>\n",
       "      <td>{'0': {'id': 23, 'object': 7412}, '1': {'id': ...</td>\n",
       "      <td>{'0': 77, '2': 289, '3': 52, '4': 142, '5': 38...</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>2</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'6': 10, '9': 16}</td>\n",
       "      <td>[-0.029045926, -0.044880282, -0.12462776, -0.0...</td>\n",
       "      <td>[0.0, 3.991218328475952, 4.932686805725098, 0....</td>\n",
       "      <td>[-0.12230616807937622, 0.20142650604248047, 0....</td>\n",
       "      <td>[-0.0009340879, -0.000552057, 0.047308944, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7414</td>\n",
       "      <td>[581, 91, 638, 123]</td>\n",
       "      <td>other</td>\n",
       "      <td>MRA</td>\n",
       "      <td>{'0': {'id': 46, 'object': 7412}, '1': {'id': ...</td>\n",
       "      <td>{'0': 402, '1': 289, '3': 377, '4': 467, '5': ...</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001645</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'5': 34, '8': 3}</td>\n",
       "      <td>[-0.023476912, -0.039044738, -0.17681217, -0.0...</td>\n",
       "      <td>[0.0, 0.9673323631286621, 9.246628761291504, 0...</td>\n",
       "      <td>[-0.2084798663854599, -0.2435063123703003, -0....</td>\n",
       "      <td>[-0.0009340879, -0.000552057, 0.047308944, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7415</td>\n",
       "      <td>[91, 288, 204, 302]</td>\n",
       "      <td>question</td>\n",
       "      <td>MANUFACTURER:</td>\n",
       "      <td>{'0': {'id': 69, 'object': 7412}, '1': {'id': ...</td>\n",
       "      <td>{'0': 88, '1': 52, '2': 377, '4': 469, '5': 46...</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>2</td>\n",
       "      <td>0.008217</td>\n",
       "      <td>13</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'13': 22, '21': 28}</td>\n",
       "      <td>[-0.035383455, -0.04307928, -0.17305261, -0.04...</td>\n",
       "      <td>[0.0, 1.8845555782318115, 1.7339874505996704, ...</td>\n",
       "      <td>[0.07169141620397568, 0.34372690320014954, 0.1...</td>\n",
       "      <td>[-0.0009340879, -0.000552057, 0.047308944, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7416</td>\n",
       "      <td>[94, 771, 114, 781]</td>\n",
       "      <td>question</td>\n",
       "      <td>cc:</td>\n",
       "      <td>{'0': {'id': 92, 'object': 7412}, '1': {'id': ...</td>\n",
       "      <td>{'0': 26, '1': 142, '2': 467, '3': 469, '5': 5...</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'0': 26, '23': 1}</td>\n",
       "      <td>[-0.028614875, -0.044609457, -0.1418788, -0.04...</td>\n",
       "      <td>[0.0, 0.8069549798965454, 3.126600503921509, 0...</td>\n",
       "      <td>[-0.1986543983221054, -0.05733171105384827, 0....</td>\n",
       "      <td>[-0.0009340879, -0.000552057, 0.047308944, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                   box  category           text  \\\n",
       "0  7412  [140, 186, 179, 200]  question          DATE:   \n",
       "1  7413  [256, 186, 292, 201]  question          TIME:   \n",
       "2  7414   [581, 91, 638, 123]     other            MRA   \n",
       "3  7415   [91, 288, 204, 302]  question  MANUFACTURER:   \n",
       "4  7416   [94, 771, 114, 781]  question            cc:   \n",
       "\n",
       "                                           relations  \\\n",
       "0  {'0': {'id': 0, 'object': 7413}, '1': {'id': 1...   \n",
       "1  {'0': {'id': 23, 'object': 7412}, '1': {'id': ...   \n",
       "2  {'0': {'id': 46, 'object': 7412}, '1': {'id': ...   \n",
       "3  {'0': {'id': 69, 'object': 7412}, '1': {'id': ...   \n",
       "4  {'0': {'id': 92, 'object': 7412}, '1': {'id': ...   \n",
       "\n",
       "                                                 gap  text_density  \\\n",
       "0  {'1': 77, '2': 402, '3': 88, '4': 26, '5': 493...      0.003663   \n",
       "1  {'0': 77, '2': 289, '3': 52, '4': 142, '5': 38...      0.003704   \n",
       "2  {'0': 402, '1': 289, '3': 377, '4': 467, '5': ...      0.000548   \n",
       "3  {'0': 88, '1': 52, '2': 377, '4': 469, '5': 46...      0.001264   \n",
       "4  {'0': 26, '1': 142, '2': 467, '3': 469, '5': 5...      0.010000   \n",
       "\n",
       "   text_number  char_density  char_number parsing_level1 parsing_level2  \\\n",
       "0            2      0.009158            5             []             []   \n",
       "1            2      0.009259            5             []             []   \n",
       "2            1      0.001645            3             []             []   \n",
       "3            2      0.008217           13             []             []   \n",
       "4            2      0.015000            3             []             []   \n",
       "\n",
       "               near_gap                                   gcn_token_number  \\\n",
       "0   {'9': 10, '13': 15}  [-0.026612815, -0.042800277, -0.17022753, -0.0...   \n",
       "1    {'6': 10, '9': 16}  [-0.029045926, -0.044880282, -0.12462776, -0.0...   \n",
       "2     {'5': 34, '8': 3}  [-0.023476912, -0.039044738, -0.17681217, -0.0...   \n",
       "3  {'13': 22, '21': 28}  [-0.035383455, -0.04307928, -0.17305261, -0.04...   \n",
       "4    {'0': 26, '23': 1}  [-0.028614875, -0.044609457, -0.1418788, -0.04...   \n",
       "\n",
       "                                   visual_embeddings  \\\n",
       "0  [0.0, 1.0358710289001465, 4.277202606201172, 0...   \n",
       "1  [0.0, 3.991218328475952, 4.932686805725098, 0....   \n",
       "2  [0.0, 0.9673323631286621, 9.246628761291504, 0...   \n",
       "3  [0.0, 1.8845555782318115, 1.7339874505996704, ...   \n",
       "4  [0.0, 0.8069549798965454, 3.126600503921509, 0...   \n",
       "\n",
       "                                      bert_large_emb  \\\n",
       "0  [-0.8346639275550842, -0.044609859585762024, 0...   \n",
       "1  [-0.12230616807937622, 0.20142650604248047, 0....   \n",
       "2  [-0.2084798663854599, -0.2435063123703003, -0....   \n",
       "3  [0.07169141620397568, 0.34372690320014954, 0.1...   \n",
       "4  [-0.1986543983221054, -0.05733171105384827, 0....   \n",
       "\n",
       "                                      gcn_bert_large  \n",
       "0  [-0.0009340879, -0.000552057, 0.047308944, -0....  \n",
       "1  [-0.0009340879, -0.000552057, 0.047308944, -0....  \n",
       "2  [-0.0009340879, -0.000552057, 0.047308944, -0....  \n",
       "3  [-0.0009340879, -0.000552057, 0.047308944, -0....  \n",
       "4  [-0.0009340879, -0.000552057, 0.047308944, -0....  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'box', 'category', 'text', 'relations', 'gap', 'text_density',\n",
       "       'text_number', 'char_density', 'char_number', 'parsing_level1',\n",
       "       'parsing_level2', 'near_gap', 'gcn_token_number', 'visual_embeddings',\n",
       "       'bert_large_emb', 'gcn_bert_large'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'box', 'category', 'text', 'relations', 'gap', 'text_density',\n",
       "       'text_number', 'char_density', 'char_number', 'parsing_level1',\n",
       "       'parsing_level2', 'near_gap', 'gcn_token_number', 'visual_embeddings',\n",
       "       'bert_large_emb', 'gcn_bert_large'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Added extra code here - DO NOT RUN\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "df_train['label'] = labelencoder.fit_transform(df_train['category'])\n",
    "df_test['label'] = labelencoder.fit_transform(df_test['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    3266\n",
       "0    2802\n",
       "2     902\n",
       "1     441\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    1077\n",
       "0     821\n",
       "2     312\n",
       "1     122\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# new_df = pd.DataFrame()\n",
    "# new_df_test = pd.DataFrame()\n",
    "\n",
    "# cols_left  = ['text', 'label','near_visual_feature','gcn_near_char_density',\\\n",
    "#                    'gcn_near_char_number','gcn_parsing1','gcn_parsing2',\\\n",
    "#                    'gcn_pos_emb','visual_embedding','gcn_bert_large']\n",
    "# cols_right = ['text', 'label', 'text_density', 'char_density',\\\n",
    "#                     'char_number', 'parsing_level1', 'parsing_level2',\\\n",
    "#                     'gcn_token_number', 'visual_embeddings', 'bert_large_emb']\n",
    "\n",
    "\n",
    "# new_df[cols_left] = df_train[cols_right]\n",
    "# new_df_test[cols_left] = df_test[cols_right]\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['text', \n",
    " 'label',\n",
    " 'near_visual_feature',\t\n",
    " 'gcn_near_char_density',\t\n",
    " 'gcn_near_char_number',              \n",
    " 'level1_parse_emb',\n",
    " 'level2_parse_emb',\n",
    " 'gcn_near_token_density',\n",
    " 'density',\n",
    " 'visual_feature',\n",
    " 'gcn_bert_predicted']\n",
    "\n",
    "\n",
    "Index(['id', 'box', 'category', 'text', 'relations', 'gap', 'text_density',\n",
    "       'text_number', 'char_density', 'char_number', 'parsing_level1',\n",
    "       'parsing_level2', 'near_gap', 'gcn_token_number', 'visual_embeddings',\n",
    "       'bert_large_emb', 'gcn_bert_large'],\n",
    "      dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "new_df = pd.DataFrame()\n",
    "new_df_test = pd.DataFrame()\n",
    "\n",
    "cols_left  = ['text', 'label','near_visual_feature','gcn_near_char_density',\\\n",
    "                   'gcn_near_char_number','level1_parse_emb','level2_parse_emb',\\\n",
    "                   'density','visual_feature','gcn_bert_predicted']\n",
    "\n",
    "cols_right = ['text', 'label', 'gcn_token_number', 'char_density',\\\n",
    "                    'char_number', 'parsing_level1', 'parsing_level2',\\\n",
    "                    'text_density', 'visual_embeddings', 'bert_large_emb']\n",
    "\n",
    "\n",
    "new_df[cols_left] = df_train[cols_right]\n",
    "new_df_test[cols_left] = df_test[cols_right]\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7411, 18)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"../funsd/df_train_docgcn_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2332, 18)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test.to_csv(\"../funsd/df_test_docgcn_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train[\"gcn_token_number\"].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_train[\"gcn_token_number\"].loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>box</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>relations</th>\n",
       "      <th>gap</th>\n",
       "      <th>text_density</th>\n",
       "      <th>text_number</th>\n",
       "      <th>char_density</th>\n",
       "      <th>char_number</th>\n",
       "      <th>parsing_level1</th>\n",
       "      <th>parsing_level2</th>\n",
       "      <th>near_gap</th>\n",
       "      <th>gcn_token_number</th>\n",
       "      <th>visual_embeddings</th>\n",
       "      <th>bert_large_emb</th>\n",
       "      <th>gcn_bert_large</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[105, 134, 158, 149]</td>\n",
       "      <td>question</td>\n",
       "      <td>Location</td>\n",
       "      <td>{'0': {'id': 0, 'object': 1}, '1': {'id': 1, '...</td>\n",
       "      <td>{'1': 267, '2': 274, '3': 105, '4': 151, '5': ...</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010063</td>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'26': 17, '42': 12}</td>\n",
       "      <td>[-0.03008558, -0.041219972, -0.21079858, -0.04...</td>\n",
       "      <td>[0.0, 0.5288188457489014, 3.1429412364959717, ...</td>\n",
       "      <td>[-0.6775245666503906, -0.5909585952758789, -0....</td>\n",
       "      <td>[-0.00082297134, -0.00088567723, 0.046493772, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[425, 130, 475, 145]</td>\n",
       "      <td>question</td>\n",
       "      <td>Division</td>\n",
       "      <td>{'0': {'id': 70, 'object': 0}, '1': {'id': 71,...</td>\n",
       "      <td>{'0': 267, '2': 81, '3': 286, '4': 268, '5': 2...</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'38': 13, '44': 13}</td>\n",
       "      <td>[-0.030569917, -0.041657943, -0.20294446, -0.0...</td>\n",
       "      <td>[0.0, 0.40805140137672424, 3.3653852939605713,...</td>\n",
       "      <td>[-0.24348104000091553, 0.060652412474155426, -...</td>\n",
       "      <td>[-0.00082297134, -0.00088567723, 0.046493772, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[432, 226, 502, 243]</td>\n",
       "      <td>header</td>\n",
       "      <td>Invitations:</td>\n",
       "      <td>{'0': {'id': 140, 'object': 0}, '1': {'id': 14...</td>\n",
       "      <td>{'0': 274, '1': 81, '3': 293, '4': 275, '5': 2...</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>2</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>12</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'11': 10, '47': 5}</td>\n",
       "      <td>[-0.03380406, -0.044938385, -0.16522531, -0.04...</td>\n",
       "      <td>[0.0, 0.1519727110862732, 0.8420601487159729, ...</td>\n",
       "      <td>[-0.5478321313858032, 0.030162598937749863, 0....</td>\n",
       "      <td>[-0.00082297134, -0.00088567723, 0.046493772, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[103, 254, 139, 269]</td>\n",
       "      <td>question</td>\n",
       "      <td>Mugs</td>\n",
       "      <td>{'0': {'id': 210, 'object': 0}, '1': {'id': 21...</td>\n",
       "      <td>{'0': 105, '1': 286, '2': 293, '4': 31, '5': 3...</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'48': 9, '49': 0, '69': 9}</td>\n",
       "      <td>[-0.028979465, -0.040293574, -0.20505819, -0.0...</td>\n",
       "      <td>[0.0, 0.07907691597938538, 3.944286823272705, ...</td>\n",
       "      <td>[-0.26809656620025635, 0.20610269904136658, -0...</td>\n",
       "      <td>[-0.00082297134, -0.00088567723, 0.046493772, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[105, 300, 157, 315]</td>\n",
       "      <td>question</td>\n",
       "      <td>Posters</td>\n",
       "      <td>{'0': {'id': 280, 'object': 0}, '1': {'id': 28...</td>\n",
       "      <td>{'0': 151, '1': 268, '2': 275, '3': 31, '5': 2...</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008974</td>\n",
       "      <td>7</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'13': 9, '50': 1}</td>\n",
       "      <td>[-0.023589646, -0.038782388, -0.20685978, -0.0...</td>\n",
       "      <td>[0.0, 0.07378455251455307, 2.7909140586853027,...</td>\n",
       "      <td>[-0.26464468240737915, -0.2642456889152527, -0...</td>\n",
       "      <td>[-0.00082297134, -0.00088567723, 0.046493772, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                   box  category          text  \\\n",
       "0   0  [105, 134, 158, 149]  question      Location   \n",
       "1   1  [425, 130, 475, 145]  question      Division   \n",
       "2   2  [432, 226, 502, 243]    header  Invitations:   \n",
       "3   3  [103, 254, 139, 269]  question          Mugs   \n",
       "4   4  [105, 300, 157, 315]  question       Posters   \n",
       "\n",
       "                                           relations  \\\n",
       "0  {'0': {'id': 0, 'object': 1}, '1': {'id': 1, '...   \n",
       "1  {'0': {'id': 70, 'object': 0}, '1': {'id': 71,...   \n",
       "2  {'0': {'id': 140, 'object': 0}, '1': {'id': 14...   \n",
       "3  {'0': {'id': 210, 'object': 0}, '1': {'id': 21...   \n",
       "4  {'0': {'id': 280, 'object': 0}, '1': {'id': 28...   \n",
       "\n",
       "                                                 gap  text_density  \\\n",
       "0  {'1': 267, '2': 274, '3': 105, '4': 151, '5': ...      0.001258   \n",
       "1  {'0': 267, '2': 81, '3': 286, '4': 268, '5': 2...      0.001333   \n",
       "2  {'0': 274, '1': 81, '3': 293, '4': 275, '5': 2...      0.001681   \n",
       "3  {'0': 105, '1': 286, '2': 293, '4': 31, '5': 3...      0.001852   \n",
       "4  {'0': 151, '1': 268, '2': 275, '3': 31, '5': 2...      0.001282   \n",
       "\n",
       "   text_number  char_density  char_number parsing_level1 parsing_level2  \\\n",
       "0            1      0.010063            8             []             []   \n",
       "1            1      0.010667            8             []             []   \n",
       "2            2      0.010084           12             []             []   \n",
       "3            1      0.007407            4             []             []   \n",
       "4            1      0.008974            7             []             []   \n",
       "\n",
       "                      near_gap  \\\n",
       "0         {'26': 17, '42': 12}   \n",
       "1         {'38': 13, '44': 13}   \n",
       "2          {'11': 10, '47': 5}   \n",
       "3  {'48': 9, '49': 0, '69': 9}   \n",
       "4           {'13': 9, '50': 1}   \n",
       "\n",
       "                                    gcn_token_number  \\\n",
       "0  [-0.03008558, -0.041219972, -0.21079858, -0.04...   \n",
       "1  [-0.030569917, -0.041657943, -0.20294446, -0.0...   \n",
       "2  [-0.03380406, -0.044938385, -0.16522531, -0.04...   \n",
       "3  [-0.028979465, -0.040293574, -0.20505819, -0.0...   \n",
       "4  [-0.023589646, -0.038782388, -0.20685978, -0.0...   \n",
       "\n",
       "                                   visual_embeddings  \\\n",
       "0  [0.0, 0.5288188457489014, 3.1429412364959717, ...   \n",
       "1  [0.0, 0.40805140137672424, 3.3653852939605713,...   \n",
       "2  [0.0, 0.1519727110862732, 0.8420601487159729, ...   \n",
       "3  [0.0, 0.07907691597938538, 3.944286823272705, ...   \n",
       "4  [0.0, 0.07378455251455307, 2.7909140586853027,...   \n",
       "\n",
       "                                      bert_large_emb  \\\n",
       "0  [-0.6775245666503906, -0.5909585952758789, -0....   \n",
       "1  [-0.24348104000091553, 0.060652412474155426, -...   \n",
       "2  [-0.5478321313858032, 0.030162598937749863, 0....   \n",
       "3  [-0.26809656620025635, 0.20610269904136658, -0...   \n",
       "4  [-0.26464468240737915, -0.2642456889152527, -0...   \n",
       "\n",
       "                                      gcn_bert_large  label  \n",
       "0  [-0.00082297134, -0.00088567723, 0.046493772, ...      3  \n",
       "1  [-0.00082297134, -0.00088567723, 0.046493772, ...      3  \n",
       "2  [-0.00082297134, -0.00088567723, 0.046493772, ...      1  \n",
       "3  [-0.00082297134, -0.00088567723, 0.046493772, ...      3  \n",
       "4  [-0.00082297134, -0.00088567723, 0.046493772, ...      3  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "id": "baSmeDdIEadM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# new_df = df_train[['text', 'label','near_visual_feature','gcn_near_char_density',\\\n",
    "#                    'gcn_near_char_number','gcn_parsing1','gcn_parsing2',\\\n",
    "#                    'gcn_bert_base','gcn_pos_emb','visual_embedding','gcn_bert_large']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "id": "cLrlbfWr-VE_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(new_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "id": "RXgrBoaeQIaX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# new_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "id": "qX1g2eqC0s4I",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# new_df_test = df_test[['text', 'label','near_visual_feature','gcn_near_char_density',\\\n",
    "#                        'gcn_near_char_number','gcn_parsing1','gcn_parsing2',\\\n",
    "#                        'gcn_bert_base','gcn_pos_emb','visual_embedding','gcn_bert_large']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "id": "tKXr_-Fh-Y5z",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(new_df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbiQjAgdSqhn",
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "id": "nvXxpfNCGER2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 100\n",
    "TRAIN_BATCH_SIZE = 16\n",
    "VALID_BATCH_SIZE = TRAIN_BATCH_SIZE*2\n",
    "# EPOCHS = 1\n",
    "LEARNING_RATE = 2e-05\n",
    "# Change the pre-trained bert model\n",
    "#tokenizer = BertTokenizer.from_pretrained('roberta-base') #Cased "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "3vWRDemOGxJD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SentimentData(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.text\n",
    "        self.targets = self.data.label\n",
    "        self.gcn_visual_feature = dataframe.near_visual_feature\n",
    "        self.visual_feature = dataframe.visual_feature\n",
    "        self.gcn_bert_base = dataframe.gcn_bert_predicted\n",
    "        self.parsing1 = dataframe.level1_parse_emb\n",
    "        self.parsing2 = dataframe.level2_parse_emb\n",
    "        self.char_density = dataframe.gcn_near_char_density\n",
    "        self.char_number = dataframe.gcn_near_char_number\n",
    "        self.density = dataframe.density\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float),\n",
    "            'density': torch.tensor(self.density[index],dtype=torch.float),\n",
    "            'gcn_bert_base': torch.tensor(self.gcn_bert_base[index],dtype=torch.float),\n",
    "            'char_density': torch.tensor(self.char_density[index],dtype=torch.float),\n",
    "            'char_number': torch.tensor(self.char_number[index],dtype=torch.float),\n",
    "            'visual_feature': torch.tensor(self.visual_feature[index],dtype=torch.float),\n",
    "            'parsing1': torch.tensor(self.parsing1[index],dtype=torch.float),\n",
    "            'parsing2': torch.tensor(self.parsing2[index],dtype=torch.float),\n",
    "            'gcn_visual_feature': torch.tensor(self.gcn_visual_feature[index],dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "id": "7Gpe9D1QHoCd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (7411, 10)\n",
      "TRAIN Dataset: (7411, 10)\n",
      "TEST Dataset: (2332, 10)\n",
      "NEW TRAIN Dataset: (6000, 10)\n",
      "NEW EVAL Dataset: (1411, 10)\n"
     ]
    }
   ],
   "source": [
    "train_size = 1\n",
    "train_data=new_df.sample(frac=train_size,random_state=200)\n",
    "#test_data=new_df.drop(train_data.index).reset_index(drop=True)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "new_train_data = train_data[:6000]\n",
    "new_eval_data = train_data[6000:].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# train, val = train.reset_index(drop=True), val.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(new_df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
    "print(\"TEST Dataset: {}\".format(new_df_test.shape))\n",
    "\n",
    "print(\"NEW TRAIN Dataset: {}\".format(new_train_data.shape))\n",
    "print(\"NEW EVAL Dataset: {}\".format(new_eval_data.shape))\n",
    "\n",
    "\n",
    "\n",
    "training_set = SentimentData(train_data, tokenizer, MAX_LEN)\n",
    "new_training_set = SentimentData(new_train_data, tokenizer, MAX_LEN)\n",
    "new_eval_set = SentimentData(new_eval_data, tokenizer, MAX_LEN)\n",
    "#testing_set = SentimentData(test_data, tokenizer, MAX_LEN)\n",
    "test_set = SentimentData(new_df_test,tokenizer,MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "c1tInLk2Eadt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "eval_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "new_training_loader = DataLoader(new_training_set, **train_params)\n",
    "#testing_loader = DataLoader(testing_set, **test_params)\n",
    "vali_loader = DataLoader(test_set, **test_params)\n",
    "\n",
    "eval_loader = DataLoader(new_eval_set, **eval_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jF12YgfxSwEr",
    "tags": []
   },
   "source": [
    "## Define the proposed classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipKk-m3pynW6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "id": "HMqQTafXEaei",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class RobertaClass(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(RobertaClass, self).__init__()\n",
    "#         #bert-base-cased 768\n",
    "#         #bert-large-cased bert-large-uncased 1024\n",
    "#         #roberta-base-cased 768\n",
    "#         #biobert\n",
    "\n",
    "#         self.l1 = AutoModel.from_pretrained('bert-base-uncased')# BERT large\n",
    "#         self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "#         self.dropout = torch.nn.Dropout(0.1)\n",
    "#         self.h1 = torch.nn.Linear(768,768)\n",
    "#         self.h2 = torch.nn.Linear(768,768)\n",
    "#         self.h3 = torch.nn.Linear(768,768)\n",
    "#         self.h4 = torch.nn.Linear(768,768)\n",
    "#         self.hidden0 = torch.nn.Linear(2304,256)\n",
    "#         self.hidden1 = torch.nn.Linear(2048,768)\n",
    "#         self.hidden2 = torch.nn.Linear(3072,512)\n",
    "\n",
    "#         self.hidden3 = torch.nn.Linear(3072,3072)\n",
    "#         self.hidden4 = torch.nn.Linear(1024,768)\n",
    "#         self.classifier = torch.nn.Linear(512, 4)\n",
    "#         self.pooling = torch.nn.MaxPool2d((2,1), stride=None)\n",
    "\n",
    "#     def forward(self,input_ids,attention_mask,token_type_ids,char_density,char_number, visual_feature,\\\n",
    "#                 gcn_bert_base,parsing1,parsing2,pos_emb,visual):\n",
    "\n",
    "#         output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "#         hidden_state = output_1[0]\n",
    "#         pooler = hidden_state[:, 0]\n",
    "#         # BERT 768 BERT / large 1024\n",
    "        \n",
    "#         # set different hidden layer, number of hidden units, regularization methods including bn and dropout\n",
    "#         pooler = self.pre_classifier(pooler)\n",
    "#         pooler = torch.nn.Tanh()(pooler)\n",
    "#         pooler = self.dropout(pooler)\n",
    "\n",
    "#         other = torch.cat((pooler.unsqueeze(1),gcn_bert_base.unsqueeze(1)),1)\n",
    "#         other = self.pooling(other).squeeze(1)\n",
    "#         other = self.h1(other)\n",
    "#         other = torch.nn.Tanh()(other)\n",
    "#         other = self.dropout(other)\n",
    "#         pooler = other\n",
    "\n",
    "\n",
    "#         parsing = torch.cat((parsing1.unsqueeze(1),parsing2.unsqueeze(1)),1)\n",
    "#         parsing = self.pooling(parsing).squeeze(1)\n",
    "#         parsing = self.h2(parsing)\n",
    "#         parsing = torch.nn.Tanh()(parsing)\n",
    "#         parsing = self.dropout(parsing)\n",
    "\n",
    "#         density = torch.cat((char_density.unsqueeze(1),char_number.unsqueeze(1)),1)\n",
    "#         density = self.pooling(density).squeeze(1)\n",
    "#         density = self.h3(density)\n",
    "#         density = torch.nn.Tanh()(density)\n",
    "#         density = self.dropout(density)\n",
    "\n",
    "#         visual = self.hidden1(visual)\n",
    "#         visual = torch.nn.Tanh()(visual)\n",
    "#         visual = self.dropout(visual)\n",
    "\n",
    "#         other = torch.cat((visual.unsqueeze(1),visual_feature.unsqueeze(1)),1)\n",
    "#         other = self.pooling(other).squeeze(1)\n",
    "#         other = self.h4(other)\n",
    "#         other = torch.nn.Tanh()(other)\n",
    "#         other = self.dropout(other)\n",
    "#         visual = other\n",
    "\n",
    "#         pooler = torch.cat((pooler,visual,parsing,char_density),1)\n",
    "#         pooler = self.hidden3(pooler)\n",
    "#         pooler = torch.nn.Tanh()(pooler)\n",
    "#         pooler = self.dropout(pooler)\n",
    "\n",
    "#         pooler = self.hidden2(pooler)\n",
    "#         pooler = torch.nn.Tanh()(pooler)\n",
    "#         pooler = self.dropout(pooler)\n",
    "\n",
    "#         output = self.classifier(pooler)\n",
    "#         return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RobertaClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RobertaClass, self).__init__()\n",
    "        #bert-base-cased 768\n",
    "        #bert-large-cased bert-large-uncased 1024\n",
    "        #roberta-base-cased 768\n",
    "        #biobert\n",
    "\n",
    "        self.l1 = AutoModel.from_pretrained(\"bert-base-uncased\")# BERT large\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.1)\n",
    "        self.hidden_cls = torch.nn.Linear(768,768)\n",
    "        self.hidden_parsing = torch.nn.Linear(768,768)\n",
    "        self.hidden_den = torch.nn.Linear(768,768)\n",
    "        self.hidden_vis = torch.nn.Linear(768,768)\n",
    "        self.hidden_vis_pro = torch.nn.Linear(2048,768)\n",
    "        self.hidden_all = torch.nn.Linear(768*2,768*2)\n",
    "        self.before_classifier = torch.nn.Linear(768*2,128)\n",
    "        self.pooling = torch.nn.MaxPool2d((2,1), stride=None)\n",
    "        self.classifier = torch.nn.Linear(128, 4)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, char_density,char_number,visual_feature,bert_cls,parsing1,parsing2,visual):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "\n",
    "        # BERT 768 BERT / large 1024\n",
    "        \n",
    "        # set different hidden layer, number of hidden units, regularization methods including bn and dropout\n",
    "        \n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.Tanh()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "\n",
    "        pooler = torch.cat((pooler.unsqueeze(1),bert_cls.unsqueeze(1)),1)\n",
    "        pooler = self.pooling(pooler).squeeze(1)\n",
    "        pooler = self.hidden_cls(pooler)\n",
    "        pooler = torch.nn.Tanh()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "\n",
    "        visual = self.hidden_vis_pro(visual)\n",
    "        visual = torch.nn.Tanh()(visual)\n",
    "        visual = self.dropout(visual)\n",
    "\n",
    "        visual = torch.cat((visual.unsqueeze(1),visual_feature.unsqueeze(1)),1)\n",
    "        visual = self.pooling(visual).squeeze(1)\n",
    "        visual = self.hidden_vis(visual)\n",
    "        visual = torch.nn.Tanh()(visual)\n",
    "        visual = self.dropout(visual)\n",
    "\n",
    "        pooler = torch.cat((pooler,visual),1)\n",
    "        pooler = self.hidden_all(pooler)\n",
    "        pooler = torch.nn.Tanh()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "\n",
    "        pooler = self.before_classifier(pooler)\n",
    "        pooler = torch.nn.Tanh()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true,
    "id": "sZ55mIPZIkp_",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (hidden_cls): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (hidden_parsing): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (hidden_den): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (hidden_vis): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (hidden_vis_pro): Linear(in_features=2048, out_features=768, bias=True)\n",
       "  (hidden_all): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "  (before_classifier): Linear(in_features=1536, out_features=128, bias=True)\n",
       "  (pooling): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (classifier): Linear(in_features=128, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = RobertaClass()\n",
    "new_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XBJjGKdS2b8",
    "tags": []
   },
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "XYZ7YuJ5InOS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  new_model.parameters(), lr=1e-05) # change learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "yPhA2V3iIpzN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calcuate_accuracy(preds, targets):\n",
    "    n_correct = (preds==targets).sum().item()\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default logging directory  `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/funsd_docgcn_experiment_1')\n",
    "new_writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(new_training_loader)\n",
    "labels = next(dataiter)['targets']\n",
    "masks = next(dataiter)['ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([[  101,  3196,  9402,  ...,     0,     0,     0],\n",
       "         [  101, 27178,  2102,  ...,     0,     0,     0],\n",
       "         [  101,  3058,   102,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  5246,   102,  ...,     0,     0,     0],\n",
       "         [  101,  6583,   102,  ...,     0,     0,     0],\n",
       "         [  101,   100,   102,  ...,     0,     0,     0]]),\n",
       " 'mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]),\n",
       " 'targets': tensor([0., 1., 3., 3., 3., 0., 0., 3., 2., 3., 3., 3., 0., 3., 0., 0.]),\n",
       " 'density': tensor([0.0020, 0.0017, 0.0010, 0.0011, 0.0038, 0.0032, 0.0008, 0.0036, 0.0011,\n",
       "         0.0022, 0.0022, 0.0011, 0.0125, 0.0046, 0.0077, 0.0024]),\n",
       " 'gcn_bert_base': tensor([[-0.5740,  0.1609,  0.0450,  ..., -0.1054,  0.7080,  0.6565],\n",
       "         [-0.1194,  0.4650, -0.1720,  ..., -0.1511,  0.7631,  0.3729],\n",
       "         [-0.6775, -0.5910, -0.0881,  ..., -0.5313,  0.9908,  0.0846],\n",
       "         ...,\n",
       "         [-0.5863, -0.0132,  0.4435,  ..., -0.2423,  0.4817,  0.5287],\n",
       "         [-0.1893,  0.0702, -0.1817,  ..., -0.4111,  0.3171,  0.6708],\n",
       "         [-0.1893,  0.0702, -0.1817,  ..., -0.4111,  0.3171,  0.6708]]),\n",
       " 'char_density': tensor([0.0101, 0.0113, 0.0041, 0.0044, 0.0229, 0.0097, 0.0068, 0.0214, 0.0050,\n",
       "         0.0073, 0.0089, 0.0064, 0.0125, 0.0231, 0.0154, 0.0024]),\n",
       " 'char_number': tensor([10., 13.,  4.,  8., 30.,  3., 26., 12., 35., 13., 12., 12.,  1.,  5.,\n",
       "          2.,  1.]),\n",
       " 'visual_feature': tensor([[0.0000, 1.6584, 5.7633,  ..., 0.0000, 0.6913, 0.0000],\n",
       "         [0.0000, 0.8001, 3.2654,  ..., 0.0000, 1.4020, 0.0000],\n",
       "         [0.0000, 3.7423, 2.7210,  ..., 0.0000, 0.0000, 0.5018],\n",
       "         ...,\n",
       "         [0.0000, 0.0176, 7.8255,  ..., 0.0000, 0.0270, 0.0000],\n",
       "         [0.0000, 0.8650, 3.5739,  ..., 0.0000, 0.0374, 0.0000],\n",
       "         [0.0000, 0.3113, 3.4536,  ..., 0.0000, 0.0000, 0.4239]]),\n",
       " 'parsing1': tensor([], size=(16, 0)),\n",
       " 'parsing2': tensor([], size=(16, 0)),\n",
       " 'gcn_visual_feature': tensor([[-0.0316, -0.0438, -0.1805,  ..., -0.0594, -0.0242, -0.0629],\n",
       "         [-0.0322, -0.0484, -0.1702,  ..., -0.0657, -0.0350, -0.1457],\n",
       "         [-0.0264, -0.0374, -0.1796,  ..., -0.0590, -0.0335, -0.0201],\n",
       "         ...,\n",
       "         [-0.0273, -0.0430, -0.1931,  ..., -0.0612, -0.0270,  0.1408],\n",
       "         [-0.0294, -0.0378, -0.2038,  ..., -0.0555, -0.0366,  0.1356],\n",
       "         [-0.0292, -0.0395, -0.1784,  ..., -0.0548, -0.0307,  0.1235]])}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3., 0., 3., 0., 0., 1., 3., 3., 0., 2., 3., 2., 0., 3., 0.])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 9 required positional arguments: 'attention_mask', 'token_type_ids', 'char_density', 'char_number', 'visual_feature', 'bert_cls', 'parsing1', 'parsing2', and 'visual'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m writer\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/torch/utils/tensorboard/writer.py:841\u001b[0m, in \u001b[0;36mSummaryWriter.add_graph\u001b[0;34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    837\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard.logging.add_graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;66;03m# A valid PyTorch model should have a 'forward' method\u001b[39;00m\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_graph(\n\u001b[0;32m--> 841\u001b[0m         \u001b[43mgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_to_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m     )\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;66;03m# Caffe2 models do not have the 'forward' method\u001b[39;00m\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcaffe2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m caffe2_pb2\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/torch/utils/tensorboard/_pytorch_graph.py:337\u001b[0m, in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _set_model_to_eval(model):\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 337\u001b[0m         trace \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_strict_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m         graph \u001b[38;5;241m=\u001b[39m trace\u001b[38;5;241m.\u001b[39mgraph\n\u001b[1;32m    339\u001b[0m         torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_jit_pass_inline(graph)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/torch/jit/_trace.py:794\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    792\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    793\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_store_inputs\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    808\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    811\u001b[0m ):\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/torch/jit/_trace.py:1056\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1055\u001b[0m     example_inputs \u001b[38;5;241m=\u001b[39m make_tuple(example_inputs)\n\u001b[0;32m-> 1056\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_method_from_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar_lookup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m        \u001b[49m\u001b[43margument_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m check_trace_method \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_get_method(method_name)\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1488\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1486\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1488\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 9 required positional arguments: 'attention_mask', 'token_type_ids', 'char_density', 'char_number', 'visual_feature', 'bert_cls', 'parsing1', 'parsing2', and 'visual'"
     ]
    }
   ],
   "source": [
    "writer.add_graph(model, masks)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "mhqvtY2SIup7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the distilbert model\n",
    "\n",
    "def train(epoch):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    output = []\n",
    "    new_model.train()\n",
    "    for _,data in tqdm(enumerate(new_training_loader, 0)):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "        visual_feature = data['visual_feature'].to(device, dtype = torch.float)\n",
    "        gcn_visual_feature = data['gcn_visual_feature'].to(device, dtype = torch.float)\n",
    "        gcn_bert_base = data['gcn_bert_base'].to(device, dtype = torch.float)\n",
    "        parsing1 = data['parsing1'].to(device, dtype = torch.float)\n",
    "        parsing2 = data['parsing2'].to(device, dtype = torch.float)\n",
    "        char_density = data['char_density'].to(device, dtype = torch.float)\n",
    "        char_number = data['char_number'].to(device, dtype = torch.float)\n",
    "\n",
    "        outputs = new_model(ids, mask, token_type_ids,char_density,char_number,gcn_visual_feature,gcn_bert_base,parsing1,parsing2,visual_feature)\n",
    "\n",
    "        loss = loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        # print(tr_loss)\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        n_correct += calcuate_accuracy(big_idx, targets)\n",
    "        # print(n_correct)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "        # print(_)\n",
    "        \n",
    "        \n",
    "        if _%1000==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            accu_step = (n_correct*100)/nb_tr_examples \n",
    "            \n",
    "            # ...log the running loss\n",
    "            new_writer.add_scalar('Mini Batch training loss',\n",
    "                            loss_step,\n",
    "                            epoch * len(new_training_loader) + _)\n",
    "            \n",
    "            new_writer.add_scalar('Mini Batch training Accuracy',\n",
    "                            accu_step,\n",
    "                            epoch * len(new_training_loader) + _)\n",
    "           \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # # When using GPU\n",
    "        optimizer.step()\n",
    "        # writer.flush()\n",
    "        \n",
    "\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "    new_writer.add_scalar(\"Epoch Train Loss\", epoch_loss, epoch)\n",
    "    new_writer.add_scalar(\"Epoch Train Accuracy\", epoch_accu, epoch)\n",
    "    \n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "id": "WHAgCduAIQRI",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375it [24:28,  3.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 0: 69.95\n",
      "Training Loss Epoch: 0.8273427864313125\n",
      "Training Accuracy Epoch: 69.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375it [24:16,  3.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 1: 81.96666666666667\n",
      "Training Loss Epoch: 0.5436455287535985\n",
      "Training Accuracy Epoch: 81.96666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375it [24:18,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 2: 85.53333333333333\n",
      "Training Loss Epoch: 0.4333462844292323\n",
      "Training Accuracy Epoch: 85.53333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375it [24:07,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 3: 88.4\n",
      "Training Loss Epoch: 0.3629546985030174\n",
      "Training Accuracy Epoch: 88.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375it [24:12,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Total Accuracy for Epoch 4: 89.78333333333333\n",
      "Training Loss Epoch: 0.31283625127871834\n",
      "Training Accuracy Epoch: 89.78333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "  train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ecydbX_S6Lg",
    "tags": []
   },
   "source": [
    "## Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "id": "bFiNcy16JLwt"
   },
   "outputs": [],
   "source": [
    "def valid(new_model, eval_loader):\n",
    "    new_model.eval()\n",
    "    n_correct = 0; n_wrong = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n",
    "    output_list = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(eval_loader, 0)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            char_den = data['char_density'].to(device, dtype = torch.float)\n",
    "            density = data['density'].to(device, dtype = torch.float)\n",
    "            visual_feature = data['visual_feature'].to(device, dtype = torch.float)\n",
    "            gcn_visual_feature = data['gcn_visual_feature'].to(device, dtype = torch.float)\n",
    "            gcn_bert_base = data['gcn_bert_base'].to(device, dtype = torch.float)\n",
    "            parsing1 = data['parsing1'].to(device, dtype = torch.float)\n",
    "            parsing2 = data['parsing2'].to(device, dtype = torch.float)\n",
    "            char_density = data['char_density'].to(device, dtype = torch.float)\n",
    "            char_number = data['char_number'].to(device, dtype = torch.float)\n",
    "            # token_density = data['token_density'].to(device, dtype = torch.float)\n",
    "            # token_number = data['token_number'].to(device, dtype = torch.float)\n",
    "\n",
    "\n",
    "            outputs = new_model(ids, mask, token_type_ids,char_density,char_number, gcn_visual_feature,gcn_bert_base,parsing1,parsing2,visual_feature).squeeze()\n",
    "            loss = loss_function(outputs, targets)\n",
    "            tr_loss += loss.item()\n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            output_list = output_list + list(big_idx)\n",
    "            n_correct += calcuate_accuracy(big_idx, targets)\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=targets.size(0)\n",
    "            \n",
    "            \n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
    "    \n",
    "    return epoch_accu,output_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "V6Yx1waSv6iF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [01:48,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss Epoch: 0.5137515389257007\n",
      "Validation Accuracy Epoch: 83.06165839829907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc,pre_list = valid(new_model, eval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true,
    "id": "CKMELmeFUaH5",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:07,  2.46s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m acc,hidden_list \u001b[38;5;241m=\u001b[39m \u001b[43mvalid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvali_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[69], line 24\u001b[0m, in \u001b[0;36mvalid\u001b[0;34m(model, testing_loader)\u001b[0m\n\u001b[1;32m     19\u001b[0m char_number \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchar_number\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# token_density = data['token_density'].to(device, dtype = torch.float)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# token_number = data['token_number'].to(device, dtype = torch.float)\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchar_density\u001b[49m\u001b[43m,\u001b[49m\u001b[43mchar_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgcn_visual_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgcn_bert_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparsing1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparsing2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvisual_feature\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     25\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs, targets)\n\u001b[1;32m     26\u001b[0m tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[62], line 23\u001b[0m, in \u001b[0;36mRobertaClass.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, char_density, char_number, visual_feature, bert_cls, parsing1, parsing2, visual)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask, token_type_ids, char_density,char_number,visual_feature,bert_cls,parsing1,parsing2,visual):\n\u001b[0;32m---> 23\u001b[0m     output_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     hidden_state \u001b[38;5;241m=\u001b[39m output_1[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     25\u001b[0m     pooler \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:958\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    949\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    951\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    952\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    953\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    956\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    957\u001b[0m )\n\u001b[0;32m--> 958\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    971\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:559\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    550\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    551\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    552\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    556\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    557\u001b[0m     )\n\u001b[1;32m    558\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 559\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:495\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    492\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    493\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 495\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    500\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/transformers/modeling_utils.py:1787\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m   1785\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m-> 1787\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:508\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    506\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m    507\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 508\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:423\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states, input_tensor):\n\u001b[0;32m--> 423\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(hidden_states)\n\u001b[1;32m    425\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# acc,hidden_list = valid(model, vali_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model, '../models/funsd_docgcn_bert_layout_segment_classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "LDxgkeaILFQ9"
   },
   "outputs": [],
   "source": [
    "model_to_test = torch.load('../models/funsd_docgcn_bert_layout_segment_classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(new_model.state_dict(), '../models/funsd_docgcn_bert_layout_segment_classifier_v3.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_8lSc-jf7bU",
    "tags": []
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "_qD3e22vE7My"
   },
   "outputs": [],
   "source": [
    "class SentimentData_test(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.text\n",
    "        self.max_len = max_len\n",
    "        self.visual_feature = dataframe.near_visual_feature\n",
    "        self.gcn_bert_base = dataframe.gcn_bert_predicted\n",
    "        self.parsing1 = dataframe.level1_parse_emb\n",
    "        self.parsing2 = dataframe.level2_parse_emb\n",
    "        self.char_density = dataframe.gcn_near_char_density\n",
    "        self.char_number = dataframe.gcn_near_char_number\n",
    "        # self.pos_emb = dataframe.gcn_pos_emb\n",
    "        self.visual = dataframe.visual_feature\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'gcn_bert_base': torch.tensor(self.gcn_bert_base[index],dtype=torch.float),\n",
    "            'char_density': torch.tensor(self.char_density[index],dtype=torch.float),\n",
    "            'char_number': torch.tensor(self.char_number[index],dtype=torch.float),\n",
    "            'visual_feature': torch.tensor(self.visual_feature[index],dtype=torch.float),\n",
    "            'parsing1': torch.tensor(self.parsing1[index],dtype=torch.float),\n",
    "            'parsing2': torch.tensor(self.parsing2[index],dtype=torch.float),\n",
    "            # 'pos_emb': torch.tensor(self.pos_emb[index],dtype=torch.float),\n",
    "            'visual': torch.tensor(self.visual[index],dtype=torch.float),\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMRN5w3RXjqB",
    "tags": []
   },
   "source": [
    "### load the test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols_left  = ['text', 'label','near_visual_feature','gcn_near_char_density',\\\n",
    "                   'gcn_near_char_number','level1_parse_emb','level2_parse_emb',\\\n",
    "                   'density','visual_feature','gcn_bert_predicted']\n",
    "\n",
    "cols_right = ['text', 'label', 'gcn_token_number', 'char_density',\\\n",
    "                    'char_number', 'parsing_level1', 'parsing_level2',\\\n",
    "                    'text_density', 'visual_embeddings', 'bert_large_emb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "id": "Zaw4D5UKFe-Z"
   },
   "outputs": [],
   "source": [
    "# new_df_true_test = new_df_test[['text', 'label','near_visual_feature','gcn_near_char_density',\\\n",
    "#                        'gcn_near_char_number','gcn_parsing1','gcn_parsing2',\\\n",
    "#                        'gcn_bert_base','gcn_pos_emb','visual_embedding','gcn_bert_large']]\n",
    "\n",
    "new_df_true_test = new_df_test[cols_left]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "id": "B0kUqjR1Fhb6"
   },
   "outputs": [],
   "source": [
    "test = SentimentData_test(new_df_true_test,tokenizer, MAX_LEN)\n",
    "testing_loader = DataLoader(test, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaClass(\n",
       "  (l1): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (hidden_cls): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (hidden_parsing): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (hidden_den): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (hidden_vis): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (hidden_vis_pro): Linear(in_features=2048, out_features=768, bias=True)\n",
       "  (hidden_all): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "  (before_classifier): Linear(in_features=1536, out_features=128, bias=True)\n",
       "  (pooling): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (classifier): Linear(in_features=128, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_docgcn = RobertaClass()\n",
    "model_docgcn.load_state_dict(torch.load('../models/funsd_docgcn_bert_layout_segment_classifier_v2.pt'))\n",
    "model_docgcn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "id": "IetKrn_SY-OT"
   },
   "outputs": [],
   "source": [
    "def test_label_generator(model_docgcn, testing_loader):\n",
    "    model_docgcn.eval()\n",
    "    n_correct = 0; n_wrong = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n",
    "    output_list = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            visual_feature = data['visual_feature'].to(device, dtype = torch.float)\n",
    "            gcn_bert_base = data['gcn_bert_base'].to(device, dtype = torch.float)\n",
    "            parsing1 = data['parsing1'].to(device, dtype = torch.float)\n",
    "            parsing2 = data['parsing2'].to(device, dtype = torch.float)\n",
    "            char_density = data['char_density'].to(device, dtype = torch.float)\n",
    "            char_number = data['char_number'].to(device, dtype = torch.float)\n",
    "            # pos_emb = data['pos_emb'].to(device, dtype = torch.float)\n",
    "            visual = data['visual'].to(device, dtype = torch.float)\n",
    "\n",
    "            # outputs = model(ids, mask, token_type_ids,visual_feature,char_density,char_number,parsing1,parsing2,gcn_bert_base,visual).squeeze()\n",
    "            outputs = model_docgcn(ids, mask, token_type_ids,char_density,char_number, visual_feature,gcn_bert_base,parsing1,parsing2,visual).squeeze()\n",
    "            \n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            output_list = output_list + list(big_idx)\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            \n",
    "    return output_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qQ_noXfKBHmn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/Users/shashanksahoo/miniconda3/envs/gpt-LLM/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2137: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "13it [00:30,  2.38s/it]"
     ]
    }
   ],
   "source": [
    "output = test_label_generator(model_docgcn, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EtOYJuQh9dy0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the predicted category id for selected test dataset.\n",
    "q = []\n",
    "for p in output:\n",
    "  q.append(p.cpu().numpy().tolist())\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vnJiHq5Lm5u5"
   },
   "outputs": [],
   "source": [
    "# getting the actual labels\n",
    "p = new_df_test['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(p), len(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "id": "lqrt7A_W8miu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      answer     0.8691    0.8331    0.8507       821\n",
      "      header     0.5974    0.3770    0.4623       122\n",
      "       other     0.5978    0.7051    0.6471       312\n",
      "    question     0.8882    0.9071    0.8976      1077\n",
      "\n",
      "    accuracy                         0.8263      2332\n",
      "   macro avg     0.7381    0.7056    0.7144      2332\n",
      "weighted avg     0.8274    0.8263    0.8248      2332\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "target_names = ['answer', 'header', 'other', 'question']\n",
    "report = classification_report(p,q, digits=4, target_names=target_names)\n",
    "matrix = confusion_matrix(p,q)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "target_names = ['answer', 'header', 'other', 'question']\n",
    "report = classification_report(p,q, digits=4, target_names=target_names)\n",
    "matrix = confusion_matrix(p,q)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "eQpJTV7RSVZW",
    "cJjfftEpSkfm",
    "B7TWqvbTppX_",
    "RbiQjAgdSqhn"
   ],
   "machine_shape": "hm",
   "name": "Funsd_Object_Detection_bert_large.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
